# Filename: materials_toolkit.py
"""
ææ–™ç§‘å­¦è®¡ç®—å·¥å…·åŒ…

ä¸»è¦åŠŸèƒ½ï¼š
1. XRDç›¸é‰´å®šä¸å³°åŒ¹é…ï¼šåŸºäºpymatgenä¸scipyå®ç°è¡å°„å³°åŒ¹é…ä¸è§’åº¦æ¼‚ç§»æ ¡å‡†
2. å…ƒç´ ä¸æ•°æ®åº“è®¿é—®ï¼šä½¿ç”¨mendeleevè·å–å…ƒç´ ç‰©æ€§ï¼Œç¤ºä¾‹é›†æˆMaterials Projectï¼ˆmp-apiï¼‰
3. ç»„åˆåˆ†æä¸å¯è§†åŒ–ï¼šå¤šææ–™æ··åˆè°±çš„ç›¸è¯†åˆ«ä¸Plotlyäº¤äº’å¼å¯è§†åŒ–

ä¾èµ–åº“ï¼š
pip install numpy scipy pymatgen mendeleev plotly mp-api
"""

import os
import json
import math
from typing import Optional, Union, List, Dict, Tuple

import numpy as np
from scipy.optimize import minimize

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    from mendeleev import element
    MENDELEEV_AVAILABLE = True
except ImportError:
    MENDELEEV_AVAILABLE = False
    print("Warning: mendeleev not available. Install with: pip install mendeleev")

try:
    from pymatgen.core import Structure
    from pymatgen.analysis.diffraction.xrd import XRDCalculator
    PYMATGEN_AVAILABLE = True
except ImportError:
    PYMATGEN_AVAILABLE = False
    print("Warning: pymatgen not available. Install with: pip install pymatgen")

# ======== å…¨å±€å¸¸é‡ï¼ˆé¿å…é­”æ³•æ•°ï¼Œé›†ä¸­ç®¡ç†ï¼‰ ========
MID_SAVE_DIR = "./mid_result/materials"
TOOL_IMAGE_DIR = "./tool_images"
DEFAULT_WAVELENGTH_CUKA = 1.5406  # Ã…, Cu KÎ±
DEFAULT_RANGE = (10.0, 90.0)      # 2Î¸èŒƒå›´ï¼Œå•ä½åº¦
DEFAULT_TOLERANCE = 0.25          # å³°åŒ¹é…å®¹å·®ï¼ˆåº¦ï¼‰
MAX_SHIFT_DEG = 1.0               # å…è®¸çš„æ•´ä½“è§’åº¦æ¼‚ç§»ï¼ˆåº¦ï¼‰
PLOT_WIDTH = 900
PLOT_HEIGHT = 500

os.makedirs(MID_SAVE_DIR, exist_ok=True)
os.makedirs(TOOL_IMAGE_DIR, exist_ok=True)

# ======== æ¼”ç¤ºæ‰€ç”¨çš„å‚è€ƒå›¾è°±ï¼ˆä»é¢˜ç›®å›¾ç‰‡è¯»å‡ºçš„å…¸å‹å³°ï¼Œä½œä¸ºå¸¸é‡ç®¡ç†ï¼‰ ========
# æ³¨æ„ï¼šè¿™äº›å‚è€ƒå³°ä»…ç”¨äºå·¥å…·æ¼”ç¤ºä¸æ•™å­¦ï¼Œå®é™…å·¥ç¨‹è¯·ç”¨æ ‡å‡†æ•°æ®åº“ï¼ˆPDFå¡ç‰‡/ICSD/MPï¼‰ç”Ÿæˆæˆ–å¯¼å…¥
REF_AG2O = {
    "name": "Ag2O",
    "peaks_2theta": [32.5, 38.0, 54.6, 65.0, 90.0],
    "intensity":   [100, 42, 36, 37, 16]
}
REF_ALN = {
    "name": "AlN",
    "peaks_2theta": [35.0, 36.7, 49.6, 59.0, 65.3, 70.8, 72.1, 80.5, 85.7],
    "intensity":   [100, 92, 33, 61, 55, 10, 43, 7, 2]
}
REF_BAS = {
    "name": "BAs",
    "peaks_2theta": [32.3, 37.2, 54.2, 64.1, 69.0, 79.0, 88.5],
    "intensity":   [100, 40, 40, 40, 21, 17, 16]
}
REF_YSF = {
    "name": "YSF",
    "peaks_2theta": [27.0, 32.0, 33.0, 43.0, 47.5, 49.0, 55.5, 60.0, 63.0, 68.0, 69.5, 79.5, 86.5, 88.5],
    "intensity":   [5, 39, 100, 89, 49, 49, 20, 11, 15, 3, 28, 8, 22, 7]
}
REF_ACOF = {
    "name": "AcOF",
    "peaks_2theta": [32.0, 36.9, 54.0, 64.0, 68.8, 79.0, 88.5],
    "intensity":   [100, 40, 40, 40, 21, 17, 16]
}

# ç»¼åˆè°±ï¼ˆç¬¬ä¸€å¹…å›¾ï¼‰æŠ½å–çš„ä¸»è¦å³°ä½ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
COMPOSITE_PATTERN = {
    "peaks_2theta": [12.5, 26.0, 27.2, 31.8, 32.3, 36.8, 37.5, 38.7, 43.2, 47.5, 49.0, 54.1, 55.0, 56.0, 60.5, 64.5, 65.0, 68.5, 70.0, 71.0, 73.5, 78.5, 79.5, 85.8, 88.5, 90.0],
    "intensity":   [1, 5, 12, 50, 100, 10, 6, 5, 12, 7, 6, 1, 20, 36, 4, 20, 37, 9, 21, 15, 13, 7, 8, 3, 9, 16]
}


# ============ ç¬¬ä¸€å±‚ï¼šåŸå­å·¥å…·å‡½æ•°ï¼ˆAtomic Toolsï¼‰ ============
def save_json_data(filename: str, data: Dict) -> dict:
    """
    å°†å­—å…¸æ•°æ®ä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼ˆFunction Callingå…¼å®¹çš„ç®€å•æŒä¹…åŒ–å·¥å…·ï¼‰
    
    åŸç†ä¸è¯´æ˜ï¼š
    - å°†ä¸­é—´ç»“æœï¼ˆå³°è¡¨ã€å‚æ•°ã€å¾—åˆ†ç­‰ï¼‰JSONåºåˆ—åŒ–ä¿å­˜ï¼Œä¾¿äºç»„åˆå‡½æ•°å¤ç”¨ä¸å®¡è®¡
    - è·¯å¾„ç»Ÿä¸€åˆ° ./mid_result/materialsï¼Œä¾¿äºç®¡ç†ä¸åç»­åŠ è½½
    
    ### ğŸ”§ æ›´æ–°åçš„ä»£ç è´¨é‡æ£€æŸ¥æ¸…å•
    - [x] æ‰€æœ‰å‡½æ•°å‚æ•°ç±»å‹ä¸ºå¯JSONåºåˆ—åŒ–
    - [x] Pythonå¯¹è±¡æ„å»ºé€»è¾‘åœ¨å‡½æ•°å†…éƒ¨
    - [x] æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼ˆå­—å…¸ï¼‰
    - [x] ç¤ºä¾‹ä½¿ç”¨åŸºç¡€ç±»å‹
    
    Args:
        filename: æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰ï¼Œå¦‚ 'peaks.json'
        data: è¯»å›¾ä¸Šé‡è¦çš„ä¿¡æ¯éœ€è¦ä¿å­˜çš„æ•°æ®å­—å…¸
    
    Returns:
        dict: {'result': filepath, 'metadata': {'size': bytes}}
    
    Example:
        >>> save_json_data('demo.json', {'a': 1})
    """
    if not isinstance(filename, str):
        raise TypeError("filenameå¿…é¡»æ˜¯å­—ç¬¦ä¸²")
    if not isinstance(data, dict):
        raise TypeError("dataå¿…é¡»æ˜¯å­—å…¸")

    filepath = os.path.join(MID_SAVE_DIR, filename)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    size = os.path.getsize(filepath)
    return {'result': filepath, 'metadata': {'size_bytes': size}}


def get_element_properties(symbol: str) -> dict:
    """
    è·å–å…ƒç´ åŸºç¡€ç‰©æ€§ï¼ˆæ¥è‡ªmendeleevæ•°æ®åº“ï¼‰
    
    åŸç†ä¸è¯´æ˜ï¼š
    - é€šè¿‡mendeleevå¿«é€ŸæŸ¥è¯¢å…ƒç´ çš„åŸå­åºæ•°ã€åŸå­é‡ã€èŒƒå¾·ååŠå¾„ç­‰ï¼›ç”¨äºä¼°ç®—æ•£å°„èƒ½åŠ›æˆ–ææ–™æ€§è´¨åˆç­›
    - æ•°æ®åº“ä¸ºæœ¬åœ°æ‰“åŒ…æ•°æ®ï¼Œè®¿é—®ç¨³å®š
    
    Args:
        symbol: å…ƒç´ ç¬¦å·ï¼Œç¤ºä¾‹'Ag','O','B','As'
    
    Returns:
        dict: {'result': {...å…ƒç´ å±æ€§...}, 'metadata': {'source': 'mendeleev'}}
    
    Example:
        >>> get_element_properties('Ag')
    """
    if not isinstance(symbol, str):
        raise TypeError("symbolå¿…é¡»ä¸ºå­—ç¬¦ä¸²")
    
    if not MENDELEEV_AVAILABLE:
        # æä¾›åŸºæœ¬çš„å…ƒç´ æ•°æ®ä½œä¸ºåå¤‡
        basic_elements = {
            'Ag': {'symbol': 'Ag', 'name': 'Silver', 'atomic_number': 47, 'atomic_weight': 107.868, 'density': 10.5, 'vdw_radius': 1.72, 'group_id': 11, 'period': 5},
            'O': {'symbol': 'O', 'name': 'Oxygen', 'atomic_number': 8, 'atomic_weight': 15.999, 'density': 0.0014, 'vdw_radius': 1.52, 'group_id': 16, 'period': 2},
            'B': {'symbol': 'B', 'name': 'Boron', 'atomic_number': 5, 'atomic_weight': 10.811, 'density': 2.34, 'vdw_radius': 1.92, 'group_id': 13, 'period': 2},
            'As': {'symbol': 'As', 'name': 'Arsenic', 'atomic_number': 33, 'atomic_weight': 74.922, 'density': 5.78, 'vdw_radius': 1.85, 'group_id': 15, 'period': 4},
            'Y': {'symbol': 'Y', 'name': 'Yttrium', 'atomic_number': 39, 'atomic_weight': 88.906, 'density': 4.47, 'vdw_radius': 2.27, 'group_id': 3, 'period': 5},
            'S': {'symbol': 'S', 'name': 'Sulfur', 'atomic_number': 16, 'atomic_weight': 32.065, 'density': 2.07, 'vdw_radius': 1.80, 'group_id': 16, 'period': 3},
            'F': {'symbol': 'F', 'name': 'Fluorine', 'atomic_number': 9, 'atomic_weight': 18.998, 'density': 0.0017, 'vdw_radius': 1.47, 'group_id': 17, 'period': 2}
        }
        if symbol in basic_elements:
            return {'result': basic_elements[symbol], 'metadata': {'source': 'basic_data'}}
        else:
            return {'result': None, 'metadata': {'error': f'Element {symbol} not in basic database', 'source': 'basic_data'}}
    
    try:
        e = element(symbol)
        props = {
            "symbol": e.symbol,
            "name": e.name,
            "atomic_number": e.atomic_number,
            "atomic_weight": float(e.atomic_weight),
            "density": float(e.density) if e.density else None,
            "vdw_radius": float(e.vdw_radius) if e.vdw_radius else None,
            "group_id": e.group_id,
            "period": e.period
        }
        return {'result': props, 'metadata': {'source': 'mendeleev'}}
    except Exception as exc:
        return {'result': None, 'metadata': {'error': str(exc), 'source': 'mendeleev'}}


def simulate_xrd_from_structure(identifier: str,
                                wavelength: float = DEFAULT_WAVELENGTH_CUKA,
                                two_theta_range: Tuple[float, float] = DEFAULT_RANGE,
                                source: str = "cif") -> dict:
    """
    ç”¨pymatgenä»ç»“æ„æ–‡ä»¶æˆ–ææ–™IDç”ŸæˆXRDå›¾è°±ï¼ˆè¿”å›å³°ä½ä¸ç›¸å¯¹å¼ºåº¦ï¼‰
    
    åŸç†ä¸è¯´æ˜ï¼š
    - ä½¿ç”¨pymatgençš„XRDCalculatorè®¡ç®—ç²‰æœ«è¡å°„ï¼Œæ”¯æŒç»™å®šæ³¢é•¿ä¸2Î¸èŒƒå›´
    - ç»“æ„å¯æ¥æºäºCIFæ–‡ä»¶æˆ–Materials Projectï¼ˆéœ€ç½‘ç»œä¸MP API Keyï¼‰
    
    Args:
        identifier: ç»“æ„æ¥æºæ ‡è¯†ï¼›å½“source='cif'æ—¶æ˜¯CIFæ–‡ä»¶è·¯å¾„ï¼›å½“source='mp'æ—¶æ˜¯ææ–™IDï¼ˆå¦‚'mp-1234'ï¼‰
        wavelength: Xå°„çº¿æ³¢é•¿ï¼ˆÃ…ï¼‰ï¼Œé»˜è®¤Cu KÎ± 1.5406 Ã…
        two_theta_range: 2Î¸èŒƒå›´ (min_deg, max_deg)
        source: 'cif'æˆ–'mp'
    
    Returns:
        dict: {
            'result': {'two_theta': List[float], 'intensity': List[float]},
            'metadata': {'source': source, 'identifier': identifier}
        }
    
    Example:
        >>> simulate_xrd_from_structure('./example.cif')
    """
    if not isinstance(identifier, str):
        raise TypeError("identifierå¿…é¡»ä¸ºå­—ç¬¦ä¸²")
    if not isinstance(wavelength, (int, float)) or wavelength <= 0:
        raise ValueError("wavelengthå¿…é¡»ä¸ºæ­£æ•°")
    if not isinstance(two_theta_range, (list, tuple)) or len(two_theta_range) != 2:
        raise ValueError("two_theta_rangeå¿…é¡»ä¸ºé•¿åº¦ä¸º2çš„åºåˆ—")
    tmin, tmax = float(two_theta_range[0]), float(two_theta_range[1])
    if tmin >= tmax:
        raise ValueError("two_theta_rangeå¿…é¡»æ»¡è¶³min < max")

    if not PYMATGEN_AVAILABLE:
        return {'result': {'two_theta': [], 'intensity': []}, 'metadata': {'error': 'pymatgen not available', 'source': source, 'identifier': identifier}}
    
    try:
        if source.lower() == "cif":
            if not os.path.isfile(identifier):
                raise FileNotFoundError(f"CIFæ–‡ä»¶ä¸å­˜åœ¨: {identifier}")
            structure = Structure.from_file(identifier)
        elif source.lower() == "mp":
            # å°è¯•ä»Materials Projectä¸‹è½½ï¼ˆå¯èƒ½éœ€è¦ç½‘ç»œä¸API Keyï¼‰
            try:
                from mp_api.client import MPRester
                with MPRester() as mpr:
                    doc = mpr.materials.summary.get_data_by_id(identifier)
                    if not doc or not getattr(doc[0], "structure", None):
                        raise ValueError("æœªä»MPè·å¾—ç»“æ„æ•°æ®")
                    structure = doc[0].structure
            except ImportError:
                raise ValueError("mp-api not available")
        else:
            raise ValueError("sourceå¿…é¡»ä¸º'cif'æˆ–'mp'")

        calc = XRDCalculator(wavelength=wavelength)
        pattern = calc.get_pattern(structure, two_theta_range=(tmin, tmax))
        # ä¿è¯å¯åºåˆ—åŒ–
        res = {'two_theta': list(pattern.x), 'intensity': list(pattern.y)}
        return {'result': res, 'metadata': {'source': source, 'identifier': identifier}}
    except Exception as exc:
        return {'result': {'two_theta': [], 'intensity': []}, 'metadata': {'error': str(exc), 'source': source, 'identifier': identifier}}


def normalize_intensity(intensity: List[float]) -> dict:
    """
    å°†å¼ºåº¦å½’ä¸€åŒ–åˆ°æœ€å¤§å€¼ä¸º100
    
    åŸç†ä¸è¯´æ˜ï¼š
    - XRDç›¸å¯¹å¼ºåº¦é€šå¸¸ç»Ÿä¸€åˆ°100ï¼Œä¾¿äºè·¨æ ·å“æ¯”è¾ƒä¸åŒ¹é…è¯„åˆ†
    - é˜²æ­¢é›¶å‘é‡ä¸è´Ÿå€¼ï¼Œå®‰å…¨å½’ä¸€åŒ–
    
    Args:
        intensity: å¼ºåº¦æ•°ç»„ï¼ˆlistï¼‰ï¼Œéè´Ÿ
    
    Returns:
        dict: {'result': List[float], 'metadata': {'max_before': float}}
    
    Example:
        >>> normalize_intensity([10, 50, 100])
    """
    if not isinstance(intensity, list):
        raise TypeError("intensityå¿…é¡»æ˜¯list")
    if len(intensity) == 0:
        return {'result': [], 'metadata': {'max_before': 0.0}}
    arr = np.array(intensity, dtype=float)
    if np.any(arr < 0):
        raise ValueError("å¼ºåº¦å¿…é¡»éè´Ÿ")
    m = float(np.max(arr))
    res = list((arr / m * 100.0) if m > 0 else arr)
    return {'result': res, 'metadata': {'max_before': m}}


def peak_matching_score(observed_2theta: List[float],
                        candidate_2theta: List[float],
                        tolerance: float = DEFAULT_TOLERANCE,
                        allow_shift: bool = True,
                        max_shift: float = MAX_SHIFT_DEG) -> dict:
    """
    è®¡ç®—å€™é€‰ç›¸ä¸è§‚æµ‹å³°çš„åŒ¹é…å¾—åˆ†ï¼ˆè€ƒè™‘æ•´ä½“è§’åº¦æ¼‚ç§»æ ¡å‡†ï¼‰
    
    åŸç†ä¸è¯´æ˜ï¼š
    - ä½¿ç”¨æœ€è¿‘é‚»åŒ¹é…ç»Ÿè®¡å‘½ä¸­æ¯”ä¾‹ï¼Œå¹¶ç”¨scipy.optimizeå¯¹å…¨å±€è§’åº¦æ¼‚ç§»Î”è¿›è¡Œæœ€ä¼˜æ ¡å‡†
    - å¾—åˆ†å®šä¹‰ï¼šå‘½ä¸­æ•° / å€™é€‰å³°æ•°ï¼ŒèŒƒå›´0-1ï¼›å¹¶ç»™å‡ºæœ€ä½³æ¼‚ç§»Î”
    
    Args:
        observed_2theta: è§‚æµ‹å³°ä½æ•°ç»„ï¼ˆåº¦ï¼‰
        candidate_2theta: å€™é€‰ææ–™å³°ä½æ•°ç»„ï¼ˆåº¦ï¼‰
        tolerance: åŒ¹é…å®¹å·®ï¼ˆåº¦ï¼‰
        allow_shift: æ˜¯å¦å…è®¸æ•´ä½“æ¼‚ç§»ä¼˜åŒ–
        max_shift: æ¼‚ç§»èŒƒå›´ï¼ˆç»å¯¹å€¼æœ€å¤§åº¦æ•°ï¼‰
    
    Returns:
        dict: {
            'result': {'score': float, 'shift_deg': float, 'matches': List[Tuple[float, float]]},
            'metadata': {'tolerance': float}
        }
    
    Example:
        >>> peak_matching_score([32.3, 37.2], [32.5, 38.0])
    """
    for arr in (observed_2theta, candidate_2theta):
        if not isinstance(arr, list):
            raise TypeError("è¾“å…¥å¿…é¡»ä¸ºlist")
        if any([not isinstance(x, (int, float)) for x in arr]):
            raise TypeError("å³°ä½å¿…é¡»ä¸ºæ•°å€¼")
    if tolerance <= 0:
        raise ValueError("toleranceå¿…é¡»ä¸ºæ­£æ•°")

    obs = np.array(observed_2theta, dtype=float)
    cand = np.array(candidate_2theta, dtype=float)

    def score_with_shift(shift: float):
        shifted = cand + shift
        matches = 0
        matched_pairs = []
        for c in shifted:
            diffs = np.abs(obs - c)
            min_d = float(np.min(diffs)) if len(diffs) > 0 else math.inf
            if min_d <= tolerance:
                matches += 1
                matched_pairs.append((c, float(obs[np.argmin(diffs)])))
        return -matches, matched_pairs  # è´Ÿå·ç”¨äºæœ€å°åŒ–

    best_shift = 0.0
    best_pairs = []
    if allow_shift:
        res = minimize(lambda s: score_with_shift(float(s))[0],
                       x0=0.0,
                       bounds=[(-max_shift, max_shift)],
                       method='L-BFGS-B')
        best_shift = float(res.x[0])
        _, best_pairs = score_with_shift(best_shift)
    else:
        _, best_pairs = score_with_shift(0.0)

    score = len(best_pairs) / max(1, len(cand))
    return {'result': {'score': float(score), 'shift_deg': best_shift, 'matches': best_pairs},
            'metadata': {'tolerance': tolerance, 'allow_shift': allow_shift}}


# ============ ç¬¬äºŒå±‚ï¼šç»„åˆå·¥å…·å‡½æ•°ï¼ˆComposite Toolsï¼‰ ============
def identify_phases_by_matching(observed_2theta: List[float],
                                observed_intensity: Optional[List[float]],
                                candidate_refs: List[Dict],
                                tolerance: float = DEFAULT_TOLERANCE,
                                allow_shift: bool = True) -> dict:
    """
    ä»å€™é€‰å‚è€ƒä¸­è¯†åˆ«æœ€å¯èƒ½çš„æ™¶ç›¸ï¼ˆå³°åŒ¹é…ä¸ç»¼åˆè¯„åˆ†ï¼‰
    
    ç§‘å­¦åŸç†ï¼š
    - XRDç›¸é‰´å®šåŸºäºå³°ä½ä¸ç›¸å¯¹å¼ºåº¦å¯¹æ¯”ï¼›å³°ä½ä¸»å¯¼åŒ¹é…ï¼Œå¼ºåº¦ä½œä¸ºæ¬¡çº§åŠ æƒ
    - é‡‡ç”¨æœ€è¿‘é‚»å³°ä½åŒ¹é…ä¸å…¨å±€è§’åº¦æ¼‚ç§»æ ¡å‡†ï¼Œæé«˜ä»ªå™¨åå·®æˆ–åº”åŠ›å¯¼è‡´çš„æ•´ä½“åç§»ä¸‹çš„é²æ£’æ€§
    
    Args:
        observed_2theta: è§‚æµ‹å³°ä½ï¼ˆåº¦ï¼‰
        observed_intensity: è§‚æµ‹ç›¸å¯¹å¼ºåº¦ï¼ˆå¯é€‰ï¼Œç”¨äºå¼ºåº¦åŠ æƒï¼‰ï¼›è‹¥Noneåˆ™ä»…å³°ä½è¯„åˆ†
        candidate_refs: å€™é€‰å‚è€ƒåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«{'name','peaks_2theta','intensity'}
        tolerance: å³°ä½åŒ¹é…å®¹å·®ï¼ˆåº¦ï¼‰
        allow_shift: æ˜¯å¦å…è®¸æ•´ä½“è§’åº¦æ¼‚ç§»ä¼˜åŒ–
    
    Returns:
        dict: {
            'result': {'ranking': List[Dict]},    # æ¯ä¸ªåŒ…å« name, score, shift_deg
            'metadata': {'tolerance': tolerance}
        }
    """
    if not isinstance(observed_2theta, list):
        raise TypeError("observed_2thetaå¿…é¡»ä¸ºlist")
    if observed_intensity is not None and not isinstance(observed_intensity, list):
        raise TypeError("observed_intensityå¿…é¡»ä¸ºlistæˆ–None")
    if not isinstance(candidate_refs, list):
        raise TypeError("candidate_refså¿…é¡»ä¸ºlist")

    # å½’ä¸€åŒ–è§‚æµ‹å¼ºåº¦ï¼ˆå¦‚æœæä¾›ï¼‰
    if observed_intensity is not None and len(observed_intensity) > 0:
        norm_obs = normalize_intensity(observed_intensity)['result']
    else:
        norm_obs = None

    results = []
    for ref in candidate_refs:
        name = ref.get("name", "Unknown")
        cand_peaks = ref.get("peaks_2theta", [])
        cand_intens = ref.get("intensity", [])
        # === using atomic tool: peak_matching_score(), and get ** returns
        pm = peak_matching_score(observed_2theta, cand_peaks, tolerance=tolerance, allow_shift=allow_shift)
        score = pm['result']['score']
        shift = pm['result']['shift_deg']
        # å¼ºåº¦åŠ æƒï¼šè‹¥è§‚æµ‹å¼ºåº¦å¯ç”¨ï¼Œè®¡ç®—åŒ¹é…å¯¹çš„å¼ºåº¦å·®æƒ©ç½š
        if norm_obs is not None and len(cand_intens) == len(cand_peaks):
            # ä¸ºæ¯ä¸ªåŒ¹é…çš„è§‚æµ‹å³°æ‰¾åˆ°è§‚æµ‹å¼ºåº¦ï¼ˆæœ€è¿‘é‚»ï¼‰
            penalty = 0.0
            for c_shifted, o in pm['result']['matches']:
                # æ‰¾åˆ°è§‚æµ‹å³°çš„ç´¢å¼•
                idx_obs = np.argmin(np.abs(np.array(observed_2theta) - o))
                I_obs = norm_obs[idx_obs]
                # æ‰¾åˆ°å€™é€‰å³°çš„åŸå§‹ç´¢å¼•ï¼ˆåå‘åŒ¹é…ï¼‰
                idx_cand = np.argmin(np.abs((np.array(cand_peaks) + shift) - c_shifted))
                I_cand = normalize_intensity(cand_intens)['result'][idx_cand]
                penalty += abs(I_obs - I_cand) / 100.0
            # å¼ºåº¦å·®æƒ©ç½šè¶Šå°è¶Šå¥½ï¼Œå°†å…¶è½¬æ¢ä¸ºå¥–åŠ±å› å­
            intensity_factor = math.exp(-penalty)
            score = score * intensity_factor
        results.append({"name": name, "score": round(float(score), 4), "shift_deg": round(float(shift), 4)})

    ranking = sorted(results, key=lambda x: x['score'], reverse=True)
    return {'result': {'ranking': ranking}, 'metadata': {'tolerance': tolerance, 'allow_shift': allow_shift}}


def merge_patterns(patterns: List[Dict]) -> dict:
    """
    å°†å¤šä¸ªå‚è€ƒå›¾è°±åˆæˆä¸ºæ··åˆè°±ï¼ˆç®€å•å åŠ ï¼‰
    
    åŸç†ä¸è¯´æ˜ï¼š
    - å°†å¤šä¸ªç›¸çš„å³°ä½åˆå¹¶å¹¶å¼ºåº¦å åŠ ï¼Œæ¨¡æ‹Ÿæ··åˆæ ·å“çš„è¡å°„å›¾è°±
    - å¼ºåº¦é‡‡ç”¨çº¿æ€§å åŠ åå½’ä¸€åŒ–
    
    Args:
        patterns: [{'two_theta': List[float], 'intensity': List[float]}]
    
    Returns:
        dict: {'result': {'two_theta': List[float], 'intensity': List[float]}, 'metadata': {}}
    """
    if not isinstance(patterns, list):
        raise TypeError("patternså¿…é¡»ä¸ºlist")
    merged = {}
    for pat in patterns:
        tt = pat.get('two_theta', [])
        I = pat.get('intensity', [])
        for t, val in zip(tt, I):
            t_round = round(float(t), 2)
            merged[t_round] = merged.get(t_round, 0.0) + float(val)
    # æ’åºå¹¶å½’ä¸€
    two_theta = sorted(merged.keys())
    intensity = [merged[t] for t in two_theta]
    intensity = normalize_intensity(intensity)['result']
    return {'result': {'two_theta': two_theta, 'intensity': intensity}, 'metadata': {'count': len(two_theta)}}


# ============ ç¬¬ä¸‰å±‚ï¼šå¯è§†åŒ–å·¥å…·ï¼ˆVisualizationï¼‰ ============
def plot_xrd_pattern(patterns: Dict[str, Dict],
                     title: str,
                     filename: Optional[str] = None) -> dict:
    """
    ä½¿ç”¨Plotlyç»˜åˆ¶XRDå›¾è°±ï¼ˆå¯å åŠ å¤šæ¡æ›²çº¿ï¼‰ï¼Œè‡ªåŠ¨ä¿å­˜åˆ° ./tool_images
    
    Args:
        patterns: å½¢å¦‚ {'Composite': {'two_theta': List, 'intensity': List}, 'Ag2O': {...}}
        title: å›¾æ ‡é¢˜
        filename: è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ
    
    Returns:
        dict: {'result': filepath, 'metadata': {'curves': list(patterns.keys())}}
    """
    try:
        import plotly.graph_objects as go
        PLOTLY_AVAILABLE = True
    except ImportError:
        PLOTLY_AVAILABLE = False
        print("Warning: plotly not available. Install with: pip install plotly")

    if filename is None:
        safe_title = "".join([c if c.isalnum() else "_" for c in title])
        filename = f"{safe_title}.png"
    filepath = os.path.join(TOOL_IMAGE_DIR, filename)

    if not PLOTLY_AVAILABLE:
        # ä½¿ç”¨matplotlibä½œä¸ºåå¤‡
        import matplotlib.pyplot as plt
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False
        
        fig, ax = plt.subplots(figsize=(12, 6))
        for name, pat in patterns.items():
            tt = pat.get('two_theta', [])
            I = pat.get('intensity', [])
            ax.plot(tt, I, 'o-', label=name, linewidth=2, markersize=4)
        
        ax.set_xlabel('2 Theta (degrees)')
        ax.set_ylabel('Intensity (a.u.)')
        ax.set_title(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"FILE_GENERATED: Plot (matplotlib) | PATH: {filepath}")
        return {'result': filepath, 'metadata': {'curves': list(patterns.keys()), 'backend': 'matplotlib'}}

    try:
        fig = go.Figure()
        for name, pat in patterns.items():
            tt = pat.get('two_theta', [])
            I = pat.get('intensity', [])
            fig.add_trace(go.Bar(x=tt, y=I, name=name, opacity=0.7))
        fig.update_layout(
            title=title,
            xaxis_title="2 Theta (degrees)",
            yaxis_title="Intensity (a.u.)",
            width=PLOT_WIDTH,
            height=PLOT_HEIGHT,
            template="plotly_white",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        fig.write_image(filepath)
        print(f"FILE_GENERATED: Plot (plotly) | PATH: {filepath}")
        return {'result': filepath, 'metadata': {'curves': list(patterns.keys()), 'backend': 'plotly'}}
    except Exception as e:
        print(f"Plotly failed: {e}, falling back to matplotlib")
        # ä½¿ç”¨matplotlibä½œä¸ºåå¤‡
        import matplotlib.pyplot as plt
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False
        
        fig, ax = plt.subplots(figsize=(12, 6))
        for name, pat in patterns.items():
            tt = pat.get('two_theta', [])
            I = pat.get('intensity', [])
            ax.plot(tt, I, 'o-', label=name, linewidth=2, markersize=4)
        
        ax.set_xlabel('2 Theta (degrees)')
        ax.set_ylabel('Intensity (a.u.)')
        ax.set_title(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"FILE_GENERATED: Plot (matplotlib) | PATH: {filepath}")
        return {'result': filepath, 'metadata': {'curves': list(patterns.keys()), 'backend': 'matplotlib'}}


# ============ ç¬¬å››å±‚ï¼šä¸»æµç¨‹æ¼”ç¤º ============
def main():
    """
    æ¼”ç¤ºå·¥å…·åŒ…è§£å†³ã€å½“å‰é—®é¢˜ã€‘+ã€è‡³å°‘2ä¸ªç›¸å…³åœºæ™¯ã€‘
    
    âš ï¸ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç¼–å†™ï¼š
    """
    print("=" * 60)
    print("åœºæ™¯1ï¼šåŸå§‹é—®é¢˜æ±‚è§£ - XRDæ··åˆè°±ç›¸é‰´å®š")
    print("=" * 60)
    print("é—®é¢˜æè¿°ï¼šåŸºäºç»™å®šçš„æ··åˆXRDå³°ä¸äº”ç§å€™é€‰ææ–™å‚è€ƒå›¾è°±ï¼Œè¯†åˆ«å¤åˆææ–™ä¸­åŒ…å«çš„ä¸‰ç§æ™¶ç›¸ã€‚")
    print("-" * 60)

    # æ­¥éª¤1ï¼šä¿å­˜è§‚æµ‹æ•°æ®ä»¥ä¾¿å®¡è®¡å’Œå¤ç”¨
    # è°ƒç”¨å‡½æ•°ï¼šsave_json_data()
    res_save = save_json_data("composite_peaks.json", COMPOSITE_PATTERN)
    print(f"FUNCTION_CALL: save_json_data | PARAMS: filename='composite_peaks.json' | RESULT: {res_save['result']}")

    # æ­¥éª¤2ï¼šæ‰§è¡Œç›¸è¯†åˆ«ï¼ˆå³°åŒ¹é… + æ¼‚ç§»æ ¡å‡†ï¼‰
    # è°ƒç”¨å‡½æ•°ï¼šidentify_phases_by_matching()
    candidates = [REF_AG2O, REF_ALN, REF_BAS, REF_YSF, REF_ACOF]
    res_id = identify_phases_by_matching(
        observed_2theta=COMPOSITE_PATTERN['peaks_2theta'],
        observed_intensity=COMPOSITE_PATTERN['intensity'],
        candidate_refs=candidates,
        tolerance=DEFAULT_TOLERANCE,
        allow_shift=True
    )
    print(f"FUNCTION_CALL: identify_phases_by_matching | PARAMS: tolerance={DEFAULT_TOLERANCE}, allow_shift=True | RESULT: {res_id['result']['ranking']}")
    top3 = [r['name'] for r in res_id['result']['ranking'][:3]]

    # æ­¥éª¤3ï¼šå¯è§†åŒ–æ··åˆè°±ä¸å‰ä¸‰ååŒ¹é…å‚è€ƒ
    # è°ƒç”¨å‡½æ•°ï¼šplot_xrd_pattern()
    composite_curve = {
        'two_theta': COMPOSITE_PATTERN['peaks_2theta'],
        'intensity': normalize_intensity(COMPOSITE_PATTERN['intensity'])['result']
    }
    ref_curves = {}
    for ref in res_id['result']['ranking'][:3]:
        name = ref['name']
        ref_data = next(item for item in candidates if item['name'] == name)
        # å°†å‚è€ƒå³°è½¬æ¢ä¸ºç»†æ£’å›¾æ›²çº¿
        ref_curves[name] = {'two_theta': ref_data['peaks_2theta'],
                            'intensity': normalize_intensity(ref_data['intensity'])['result']}
    vis_input = {"Composite": composite_curve}
    vis_input.update(ref_curves)
    res_plot = plot_xrd_pattern(vis_input, title="åœºæ™¯1_æ··åˆè°±ä¸å‰ä¸‰åŒ¹é…å‚è€ƒ")
    print(f"FUNCTION_CALL: plot_xrd_pattern | PARAMS: title='åœºæ™¯1_æ··åˆè°±ä¸å‰ä¸‰åŒ¹é…å‚è€ƒ' | RESULT: {res_plot['result']}")

    print(f"âœ“ åœºæ™¯1æœ€ç»ˆç­”æ¡ˆï¼šè¯†åˆ«åˆ°çš„ä¸‰ç§æ™¶ç›¸å€™é€‰ä¸º {', '.join(top3)}\n")

    print("=" * 60)
    print("åœºæ™¯2ï¼šå‚æ•°æ‰«æ - å®¹å·®å¯¹è¯†åˆ«ç¨³å®šæ€§çš„å½±å“")
    print("=" * 60)
    print("é—®é¢˜æè¿°ï¼šåœ¨ä¸åŒå³°ä½åŒ¹é…å®¹å·®ä¸‹ï¼ˆ0.10-0.50åº¦ï¼‰ï¼Œè¯„ä¼°è¯†åˆ«ç»“æœçš„é²æ£’æ€§ã€‚")
    print("-" * 60)

    tolerances = [0.10, 0.20, 0.30, 0.40, 0.50]
    scan_results = []
    for tol in tolerances:
        # è°ƒç”¨å‡½æ•°ï¼šidentify_phases_by_matching()
        res_scan = identify_phases_by_matching(
            observed_2theta=COMPOSITE_PATTERN['peaks_2theta'],
            observed_intensity=COMPOSITE_PATTERN['intensity'],
            candidate_refs=candidates,
            tolerance=tol,
            allow_shift=True
        )
        ranking = [r['name'] for r in res_scan['result']['ranking'][:3]]
        scan_results.append({'tolerance': tol, 'top3': ranking})
        print(f"FUNCTION_CALL: identify_phases_by_matching | PARAMS: tolerance={tol}, allow_shift=True | RESULT: {ranking}")

    # ä¿å­˜æ‰«æç»“æœ
    res_save_scan = save_json_data("tolerance_scan.json", {"scan_results": scan_results})
    print(f"FUNCTION_CALL: save_json_data | PARAMS: filename='tolerance_scan.json' | RESULT: {res_save_scan['result']}")
    print("âœ“ åœºæ™¯2å®Œæˆï¼šå®¹å·®æ‰«æç»“æœå·²ç”Ÿæˆå¹¶ä¿å­˜\n")

    # print("=" * 60)
    # print("åœºæ™¯3ï¼šæ•°æ®åº“é›†æˆ - å…ƒç´ ç‰©æ€§æŸ¥è¯¢ä¸ç»“æ„è°±æ¨¡æ‹Ÿç¤ºä¾‹")
    # print("=" * 60)
    # print("é—®é¢˜æè¿°ï¼šæŸ¥è¯¢Agã€Bã€Asã€Yã€Sã€Fçš„å…ƒç´ å±æ€§ï¼Œå¹¶æ¼”ç¤ºä»CIF/MPç»“æ„ç”ŸæˆXRDè°±çš„æµç¨‹ã€‚")
    # print("-" * 60)

    # # æ­¥éª¤1ï¼šå…ƒç´ å±æ€§æŸ¥è¯¢
    # # è°ƒç”¨å‡½æ•°ï¼šget_element_properties()
    # elems = ['Ag', 'B', 'As', 'Y', 'S', 'F']
    # elem_props = {}
    # for e in elems:
    #     res_e = get_element_properties(e)
    #     elem_props[e] = res_e['result']
    #     print(f"FUNCTION_CALL: get_element_properties | PARAMS: symbol='{e}' | RESULT: {res_e['result'] and res_e['result'].get('atomic_number')}")

    # res_save_elems = save_json_data("element_props.json", elem_props)
    # print(f"FUNCTION_CALL: save_json_data | PARAMS: filename='element_props.json' | RESULT: {res_save_elems['result']}")

    # # æ­¥éª¤2ï¼šç»“æ„è°±æ¨¡æ‹Ÿï¼ˆæ¼”ç¤ºæ¥å£ï¼Œè‹¥æ— æ–‡ä»¶æˆ–ç½‘ç»œåˆ™è¿”å›ç©ºè°±ï¼‰
    # # è°ƒç”¨å‡½æ•°ï¼šsimulate_xrd_from_structure()
    # demo_cif_path = "./example.cif"  # æ¼”ç¤ºè·¯å¾„ï¼›è‹¥ä¸å­˜åœ¨å°†è§¦å‘å®‰å…¨é”™è¯¯å¤„ç†
    # res_sim = simulate_xrd_from_structure(demo_cif_path, wavelength=DEFAULT_WAVELENGTH_CUKA, source="cif")
    # print(f"FUNCTION_CALL: simulate_xrd_from_structure | PARAMS: identifier='{demo_cif_path}', source='cif' | RESULT: len(two_theta)={len(res_sim['result']['two_theta'])}")

    # # ä¿å­˜æ¨¡æ‹Ÿè°±æˆ–è€…ç©ºè°±
    # res_save_sim = save_json_data("simulated_xrd.json", res_sim['result'])
    # print(f"FUNCTION_CALL: save_json_data | PARAMS: filename='simulated_xrd.json' | RESULT: {res_save_sim['result']}")
    # print("âœ“ åœºæ™¯3å®Œæˆï¼šå…ƒç´ å±æ€§ä¸ç»“æ„è°±æ¥å£æ¼”ç¤ºå·²å®Œæˆ\n")

    # print("=" * 60)
    # print("å·¥å…·åŒ…æ¼”ç¤ºå®Œæˆ")
    # print("=" * 60)
    # print("æ€»ç»“ï¼š")
    # print("- åœºæ™¯1å±•ç¤ºäº†è§£å†³åŸå§‹é—®é¢˜çš„å®Œæ•´æµç¨‹")
    # print("- åœºæ™¯2å±•ç¤ºäº†å·¥å…·çš„å‚æ•°æ³›åŒ–èƒ½åŠ›")
    # print("- åœºæ™¯3å±•ç¤ºäº†å·¥å…·ä¸æ•°æ®åº“çš„é›†æˆèƒ½åŠ›")

    # # åŸå§‹é¢˜ç›®æ­£ç¡®ç­”æ¡ˆæ ¡å‡†è¾“å‡ºï¼ˆæ¥è‡ªæ ¡å‡†æ¨ç†è¿‡ç¨‹ï¼‰
    # final_answer = "Agâ‚‚O, BAs, YSF"
    # print(f"FINAL_ANSWER: {final_answer}")


if __name__ == "__main__":
    main()