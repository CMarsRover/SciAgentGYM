"""
æ•°æ®åŠ è½½å’Œå¤„ç†æ¨¡å—
"""
import json
import re
import base64
from copy import deepcopy
from pathlib import Path
from typing import Any, Dict, List, Optional

from gym.config.dataset_config import (
    get_dataset_entry,
    get_current_dataset_key,
    get_trace_root,
)

def ensure_metadata_summary(case_data, default_test_type=None):
    """Ensure cases carry a compact metadata summary for downstream stats/traces."""
    if not isinstance(case_data, dict):
        return {}

    metadata = case_data.get('metadata')
    if not isinstance(metadata, dict):
        metadata = {}

    # Copy existing summary if present so we don't drop precomputed values
    summary = dict(case_data.get('metadata_summary') or {})

    subject = metadata.get('subject')
    if subject:
        summary['subject'] = subject

    topic = metadata.get('topic')
    if topic:
        summary['topic'] = topic

    test_type = metadata.get('test_type') or default_test_type or summary.get('test_type')
    if test_type:
        metadata['test_type'] = test_type
        summary['test_type'] = test_type

    original_id = metadata.get('original_question_id') or case_data.get('original_id')
    if original_id:
        original_id = str(original_id)
        metadata['original_question_id'] = original_id
        summary['original_question_id'] = original_id

    # Provide a stable composite key that is handy for group-by statistics
    if subject and topic:
        summary['subject_topic_key'] = f"{subject}::{topic}"

    # Remove empty values
    summary = {k: v for k, v in summary.items() if v not in (None, '', [], {})}

    case_data['metadata'] = metadata
    if summary:
        case_data['metadata_summary'] = summary
    else:
        case_data.pop('metadata_summary', None)

    return case_data.get('metadata_summary', {})


def load_test_cases_from_dataset():
    """ä»dataset/data_toolusage.jsonåŠ è½½æµ‹è¯•æ¡ˆä¾‹"""
    try:
        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        project_root = Path(__file__).parent.parent.parent
        data_path = project_root / 'dataset' / 'merged_questions_augmented_generated.json'
        with open(data_path, 'r', encoding='utf-8') as f:
            cases = json.load(f)

        for case in cases:
            ensure_metadata_summary(case, default_test_type='normal')
        return cases
    except Exception as e:
        print(f"åŠ è½½æµ‹è¯•æ¡ˆä¾‹å¤±è´¥: {e}")
        return []


def group_cases_by_subject(cases: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """æŒ‰ç…§ metadata.subject å¯¹æµ‹è¯•æ¡ˆä¾‹è¿›è¡Œåˆ†ç»„"""
    subject_map: Dict[str, List[Dict[str, Any]]] = {}
    for case in cases:
        metadata = case.get('metadata') or {}
        subject = metadata.get('subject') or 'æœªçŸ¥ç§‘ç›®'
        subject_map.setdefault(subject, []).append(case)
    return subject_map


def group_cases_by_topic(
    cases: List[Dict[str, Any]],
    fallback: str = 'å…¶ä»–',
) -> Dict[str, List[Dict[str, Any]]]:
    """æŒ‰ç…§ metadata.topic å¯¹æµ‹è¯•æ¡ˆä¾‹è¿›è¡Œåˆ†ç»„ï¼Œç¼ºå¤±å­—æ®µå½’ä¸º fallback"""
    topic_map: Dict[str, List[Dict[str, Any]]] = {}
    for case in cases:
        metadata = case.get('metadata') or {}
        if not isinstance(metadata, dict):
            metadata = {}

        topic_raw = metadata.get('topic')
        if not topic_raw:
            summary = case.get('metadata_summary') or {}
            if isinstance(summary, dict):
                topic_raw = summary.get('topic')

        topic = str(topic_raw).strip() if topic_raw else ''
        key = topic or fallback
        topic_map.setdefault(key, []).append(case)
    return topic_map


def deduplicate_usage_tool_entries(entries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ç¡®ä¿æ¯ä¸ªå·¥å…·åç§°å”¯ä¸€ï¼ŒåŒæ—¶æ¸…ç†ç±»å†…é‡å¤å·¥å…·"""
    global_seen = set()
    deduped_entries: List[Dict[str, Any]] = []
    duplicates_removed = 0

    for entry in entries:
        if not isinstance(entry, dict):
            deduped_entries.append(entry)
            continue

        if 'class_name' in entry and isinstance(entry.get('tools'), list):
            class_tools = []
            for tool in entry.get('tools', []):
                if not isinstance(tool, dict):
                    class_tools.append(tool)
                    continue
                func_meta = tool.get('function') or {}
                name = func_meta.get('name')
                if name and name in global_seen:
                    duplicates_removed += 1
                    continue
                if name:
                    global_seen.add(name)
                class_tools.append(tool)

            if class_tools:
                class_entry = deepcopy(entry)
                class_entry['tools'] = class_tools
                deduped_entries.append(class_entry)
            else:
                duplicates_removed += 1
            continue

        func_meta = entry.get('function') or {}
        name = func_meta.get('name')
        if name and name in global_seen:
            duplicates_removed += 1
            continue
        if name:
            global_seen.add(name)
        deduped_entries.append(entry)

    if duplicates_removed:
        print(f"âš ï¸ å·¥å…·åˆ—è¡¨å»é™¤äº† {duplicates_removed} ä¸ªé‡å¤å·¥å…·åç§°")

    return deduped_entries


def aggregate_usage_tool_protocol_for_cases(cases: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """èšåˆåŒä¸€æ‰¹æ¡ˆä¾‹çš„ usage_tool_protocolï¼Œå»é‡å¹¶ä¿ç•™åŸå§‹ç»“æ„"""
    aggregated: List[Dict[str, Any]] = []
    seen_keys = set()
    class_entries: Dict[str, Dict[str, Any]] = {}

    for case in cases:
        protocols = case.get('usage_tool_protocol') or []
        for proto in protocols:
            if not isinstance(proto, dict):
                continue

            func_block = proto.get('function')
            if isinstance(func_block, dict) and func_block.get('name'):
                func_name = func_block.get('name')
                addl = proto.get('additionalProperties') or {}
                func_path = addl.get('function_path')
                key = ('function', func_name, func_path)
                if key in seen_keys:
                    continue
                seen_keys.add(key)
                aggregated.append(deepcopy(proto))
                continue

            if 'class_name' in proto and isinstance(proto.get('tools'), list):
                class_name = proto.get('class_name') or 'anonymous_class'
                key = ('class', class_name)
                if key not in seen_keys:
                    class_entry = deepcopy(proto)
                    if not isinstance(class_entry.get('tools'), list):
                        class_entry['tools'] = []
                    aggregated.append(class_entry)
                    class_entries[class_name] = class_entry
                    seen_keys.add(key)
                else:
                    class_entry = class_entries.get(class_name)
                    if class_entry is None:
                        continue

                existing_tools = class_entry.get('tools') or []
                existing_keys = {
                    (
                        (tool.get('function') or {}).get('name'),
                        ((tool.get('additionalProperties') or {}).get('function_path'))
                    )
                    for tool in existing_tools
                    if isinstance(tool, dict)
                }
                for nested_tool in proto.get('tools', []):
                    if not isinstance(nested_tool, dict):
                        continue
                    nested_func = nested_tool.get('function') or {}
                    nested_name = nested_func.get('name')
                    nested_path = (nested_tool.get('additionalProperties') or {}).get('function_path')
                    nested_key = (nested_name, nested_path)
                    if nested_key in existing_keys:
                        continue
                    existing_keys.add(nested_key)
                    existing_tools.append(deepcopy(nested_tool))
                class_entry['tools'] = existing_tools
                continue

            serialized = json.dumps(proto, sort_keys=True, ensure_ascii=False)
            key = ('raw', serialized)
            if key in seen_keys:
                continue
            seen_keys.add(key)
            aggregated.append(deepcopy(proto))

    return deduplicate_usage_tool_entries(aggregated)


def load_augmented_test_cases_from_dataset():
    """ä»dataset/merged_questions_augmented.jsonåŠ è½½å¢å¼ºç‰ˆæµ‹è¯•æ¡ˆä¾‹ï¼ˆåå‘æµ‹è¯•ï¼‰
    
    è¿™ä¸ªå‡½æ•°å°†augmented_versionsä¸­çš„å†…å®¹è½¬æ¢ä¸ºç‹¬ç«‹çš„æµ‹è¯•æ¡ˆä¾‹ï¼Œ
    ä½¿ç”¨augmented_questionä½œä¸ºé—®é¢˜ï¼Œfinal_answerä½œä¸ºæ ‡å‡†ç­”æ¡ˆ
    
    Returns:
        list: å¢å¼ºç‰ˆæµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ˆä¾‹åŒ…å«ï¼š
        - id: åŸå§‹æ¡ˆä¾‹ID + å¢å¼ºç‰ˆæœ¬ç´¢å¼•ï¼ˆå¦‚ "1_aug_0"ï¼‰
        - question: augmented_question
        - answer: final_answer
        - metadata: ä»åŸå§‹æ¡ˆä¾‹ç»§æ‰¿ï¼Œä½†ä½¿ç”¨final_answerä½œä¸ºgolden_answer
        - original_id: åŸå§‹æ¡ˆä¾‹ID
        - augmented_index: å¢å¼ºç‰ˆæœ¬ç´¢å¼•
    """
    try:
        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        project_root = Path(__file__).parent.parent.parent
        data_path = project_root / 'dataset' / 'merged_questions_augmented_generated.json'
        with open(data_path, 'r', encoding='utf-8') as f:
            original_cases = json.load(f)
        
        augmented_cases = []
        
        for case in original_cases:
            original_id = case.get('id')
            augmented_versions = case.get('augmented_versions', [])
            
            # å¦‚æœæ²¡æœ‰å¢å¼ºç‰ˆæœ¬ï¼Œè·³è¿‡
            if not augmented_versions:
                continue
            
            # ä¸ºæ¯ä¸ªå¢å¼ºç‰ˆæœ¬åˆ›å»ºç‹¬ç«‹çš„æµ‹è¯•æ¡ˆä¾‹
            for aug_index, aug_version in enumerate(augmented_versions):
                augmented_question = aug_version.get('augmented_question')
                final_answer = aug_version.get('final_answer')
                
                # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                if not augmented_question or not final_answer:
                    print(f"è·³è¿‡æ¡ˆä¾‹ {original_id} çš„å¢å¼ºç‰ˆæœ¬ {aug_index}ï¼šç¼ºå°‘å¿…è¦å­—æ®µ")
                    continue
                
                # åˆ›å»ºæ–°çš„æµ‹è¯•æ¡ˆä¾‹
                augmented_case = {
                    'id': f"{original_id}_aug_{aug_index}",
                    'original_id': original_id,
                    'augmented_index': aug_index,
                    'question': augmented_question,
                    'answer': str(final_answer),  # å°†final_answerè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä¿æŒä¸åŸå§‹æ ¼å¼ä¸€è‡´
                    'metadata': {
                        # ç»§æ‰¿åŸå§‹æ¡ˆä¾‹çš„å…ƒæ•°æ®
                        'subject': case.get('metadata', {}).get('subject', ''),
                        'topic': case.get('metadata', {}).get('topic', ''),
                        'image_path': case.get('metadata', {}).get('image_path', []),
                        'solution_steps': aug_version.get('solution_outline', []),  # ä½¿ç”¨å¢å¼ºç‰ˆæœ¬çš„è§£å†³æ­¥éª¤
                        'tool_expected': case.get('metadata', {}).get('tool_expected', []),
                        # ä½¿ç”¨final_answerä½œä¸ºgolden_answer
                        'golden_answer': [final_answer] if isinstance(final_answer, dict) else [{'final_answer': final_answer}],
                        'original_question_id': str(original_id),
                        'test_type': 'augmented',  # æ ‡è®°ä¸ºå¢å¼ºç‰ˆæµ‹è¯•
                        'verification': aug_version.get('verification', ''),  # æ·»åŠ éªŒè¯ä¿¡æ¯
                    },
                    # ä¿ç•™åŸå§‹çš„å·¥å…·åè®®
                    'usage_tool_protocol': case.get('usage_tool_protocol', []),
                    # ä¿å­˜å®Œæ•´çš„å¢å¼ºç‰ˆæœ¬ä¿¡æ¯
                    'augmented_version_data': aug_version
                }

                ensure_metadata_summary(augmented_case, default_test_type='augmented')
                augmented_cases.append(augmented_case)
        
        print(f"æˆåŠŸåŠ è½½äº† {len(augmented_cases)} ä¸ªå¢å¼ºç‰ˆæµ‹è¯•æ¡ˆä¾‹")
        return augmented_cases
        
    except Exception as e:
        print(f"åŠ è½½å¢å¼ºç‰ˆæµ‹è¯•æ¡ˆä¾‹å¤±è´¥: {e}")
        return []


def load_refined_test_cases_from_dataset(
    dataset_key: Optional[str] = None,
    dataset_path: Optional[str] = None,
):
    """ä»é…ç½®çš„æ•°æ®é›†ä¸­åŠ è½½ç²¾ç‚¼ç‰ˆæµ‹è¯•æ¡ˆä¾‹
    
    è¿™ä¸ªå‡½æ•°å°†refined_versionsä¸­çš„å†…å®¹è½¬æ¢ä¸ºç‹¬ç«‹çš„æµ‹è¯•æ¡ˆä¾‹ï¼Œ
    ä½¿ç”¨refined_questionä½œä¸ºé—®é¢˜ï¼Œfinal_answerä½œä¸ºæ ‡å‡†ç­”æ¡ˆ
    
    Returns:
        list: ç²¾ç‚¼ç‰ˆæµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ˆä¾‹åŒ…å«ï¼š
        - id: åŸå§‹æ¡ˆä¾‹ID + ç²¾ç‚¼ç‰ˆæœ¬ç´¢å¼•ï¼ˆå¦‚ "1_ref_0"ï¼‰
        - question: refined_question
        - answer: final_answer
        - metadata: ä»åŸå§‹æ¡ˆä¾‹ç»§æ‰¿ï¼Œä½†ä½¿ç”¨final_answerä½œä¸ºgolden_answer
        - original_id: åŸå§‹æ¡ˆä¾‹ID
        - refined_index: ç²¾ç‚¼ç‰ˆæœ¬ç´¢å¼•
    """
    try:
        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        project_root = Path(__file__).parent.parent.parent
        if dataset_path:
            data_path = Path(dataset_path)
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if not data_path.is_absolute():
                # å°è¯•ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                abs_path = project_root / data_path
                if abs_path.exists():
                    data_path = abs_path
                else:
                    # å°è¯•ç›¸å¯¹äº gym ç›®å½•
                    gym_dir = Path(__file__).parent.parent
                    abs_path = gym_dir / data_path
                    if abs_path.exists():
                        data_path = abs_path
                    else:
                        # æœ€åå°è¯•ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„è·¯å¾„ï¼ˆå¯èƒ½æ˜¯ç»å¯¹è·¯å¾„çš„å­—ç¬¦ä¸²ï¼‰
                        data_path = Path(dataset_path).resolve()
            resolved_dataset_key = dataset_key or get_current_dataset_key()
        else:
            entry = get_dataset_entry(dataset_key)
            data_path = entry.dataset_path
            resolved_dataset_key = entry.key
        trace_root = get_trace_root(resolved_dataset_key)
        with open(data_path, 'r', encoding='utf-8') as f:
            original_cases = json.load(f)
        
        refined_cases = []
        
        for case in original_cases:
            original_id = case.get('id')
            refined_versions = case.get('refined_versions', [])
            
            # å¦‚æœæ²¡æœ‰ç²¾ç‚¼ç‰ˆæœ¬ï¼Œè·³è¿‡
            if not refined_versions:
                continue
            
            # ä¸ºæ¯ä¸ªç²¾ç‚¼ç‰ˆæœ¬åˆ›å»ºç‹¬ç«‹çš„æµ‹è¯•æ¡ˆä¾‹
            for ref_index, ref_version in enumerate(refined_versions):
                refined_question = ref_version.get('refined_question')
                final_answer = ref_version.get('final_answer')
                
                # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                if not refined_question or not final_answer:
                    print(f"è·³è¿‡æ¡ˆä¾‹ {original_id} çš„ç²¾ç‚¼ç‰ˆæœ¬ {ref_index}ï¼šç¼ºå°‘å¿…è¦å­—æ®µ")
                    continue
                
                # åˆ›å»ºæ–°çš„æµ‹è¯•æ¡ˆä¾‹
                refined_case = {
                    'id': f"{original_id}_ref_{ref_index}",
                    'original_id': original_id,
                    'refined_index': ref_index,
                    'question': refined_question,
                    'answer': str(final_answer),  # å°†final_answerè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä¿æŒä¸åŸå§‹æ ¼å¼ä¸€è‡´
                    'metadata': {
                        # ç»§æ‰¿åŸå§‹æ¡ˆä¾‹çš„å…ƒæ•°æ®
                        'subject': case.get('metadata', {}).get('subject', ''),
                        'topic': case.get('metadata', {}).get('topic', ''),
                        'image_path': case.get('metadata', {}).get('image_path', []),
                        'solution_steps': case.get('metadata', {}).get('solution_steps', []),
                        'tool_expected': case.get('metadata', {}).get('tool_expected', []),
                        # ä½¿ç”¨final_answerä½œä¸ºgolden_answer
                        'golden_answer': [final_answer] if isinstance(final_answer, dict) else [{'final_answer': final_answer}],
                        'original_question_id': str(original_id),
                        'test_type': 'refined',  # æ ‡è®°ä¸ºç²¾ç‚¼ç‰ˆæµ‹è¯•
                        'dataset_key': resolved_dataset_key,
                        'trace_root': str(trace_root),
                    },
                    # ä¿ç•™åŸå§‹çš„å·¥å…·åè®®
                    'usage_tool_protocol': case.get('usage_tool_protocol', []),
                    # ä¿å­˜å®Œæ•´çš„ç²¾ç‚¼ç‰ˆæœ¬ä¿¡æ¯
                    'refined_version_data': ref_version
                }

                ensure_metadata_summary(refined_case, default_test_type='refined')
                refined_cases.append(refined_case)
        
        print(f"æˆåŠŸåŠ è½½äº† {len(refined_cases)} ä¸ªç²¾ç‚¼ç‰ˆæµ‹è¯•æ¡ˆä¾‹ (æ•°æ®é›†: {resolved_dataset_key})")
        return refined_cases
        
    except Exception as e:
        print(f"åŠ è½½ç²¾ç‚¼ç‰ˆæµ‹è¯•æ¡ˆä¾‹å¤±è´¥: {e}")
        return []


def extract_image_paths(question_text):
    """ä»é—®é¢˜æ–‡æœ¬ä¸­æå–å›¾ç‰‡è·¯å¾„
    
    Args:
        question_text: é—®é¢˜æ–‡æœ¬ï¼Œå¯èƒ½åŒ…å« <images/filename.ext> æ ¼å¼çš„å›¾ç‰‡è·¯å¾„
        
    Returns:
        tuple: (clean_question_text, image_paths_list)
    """
    if not question_text:
        return question_text, []
    
    # åŒ¹é… <images/filename.ext> æ ¼å¼çš„å›¾ç‰‡è·¯å¾„
    image_pattern = r'<images/([^>]+)>'
    image_matches = re.findall(image_pattern, question_text)
    
    # ä»é—®é¢˜æ–‡æœ¬ä¸­ç§»é™¤å›¾ç‰‡æ ‡ç­¾
    clean_question = re.sub(image_pattern, '', question_text).strip()
    
    return clean_question, image_matches


def normalize_image_path(image_path_str: str) -> str:
    """å°†æ—§çš„å›¾ç‰‡è·¯å¾„è½¬æ¢ä¸ºæ–°çš„ç»Ÿä¸€è·¯å¾„æ ¼å¼
    
    å°†ä»¥ä¸‹æ ¼å¼çš„è·¯å¾„ï¼š
    - "failed_question_images/xxx.jpg"
    - "filtered_images/xxx.jpg"
    - "/sfe_images/xxx.png" æˆ– "sfe_images/xxx.png"
    - "/r_bench/images/xxx.png" æˆ– "r_bench/images/xxx.png"
    
    è½¬æ¢ä¸ºï¼š
    - "gym/test_images/xxx.png" (ç›´æ¥ä¿å­˜åœ¨ test_images ç›®å½•ä¸‹ï¼Œä¸ä¿ç•™å­ç›®å½•ç»“æ„)
    
    Args:
        image_path_str: åŸå§‹å›¾ç‰‡è·¯å¾„
        
    Returns:
        str: è½¬æ¢åçš„ç»Ÿä¸€è·¯å¾„æ ¼å¼
    """
    if not image_path_str or not isinstance(image_path_str, str):
        return image_path_str
    
    # ç§»é™¤å¼€å¤´çš„ / å’Œ ./
    path_str = image_path_str.lstrip('/').lstrip('./')
    
    # å¦‚æœå·²ç»æ˜¯æ–°æ ¼å¼ï¼Œç›´æ¥è¿”å›
    if path_str.startswith('gym/test_images/'):
        return path_str
    
    # æå–æ–‡ä»¶åï¼ˆä¸åŒ…å«ç›®å½•ç»“æ„ï¼‰
    path_obj = Path(path_str)
    filename = path_obj.name
    
    # ç»Ÿä¸€è½¬æ¢ä¸º .png æ‰©å±•å
    if path_obj.suffix:
        filename = path_obj.stem + '.png'
    else:
        # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œå°è¯•ä»åŸè·¯å¾„è·å–
        original_ext = Path(image_path_str).suffix
        if original_ext:
            filename = path_obj.name.rsplit('.', 1)[0] + '.png'
        else:
            filename = path_obj.name + '.png'
    
    # ç›´æ¥ä¿å­˜åœ¨ gym/test_images/ ç›®å½•ä¸‹ï¼Œä¸ä¿ç•™å­ç›®å½•ç»“æ„
    new_path = f"gym/test_images/{filename}"
    
    return new_path


def load_image_as_base64(image_path_or_filename):
    """åŠ è½½å›¾ç‰‡æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64ç¼–ç 
    
    Args:
        image_path_or_filename: å›¾ç‰‡æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶å
        æ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
        - "filename.jpg" (åœ¨imagesç›®å½•ä¸‹æŸ¥æ‰¾)
        - "failed_question_images/filename.jpg" (ç›¸å¯¹è·¯å¾„)
        - "gym/test_images/failed_question_images/filename.png" (æ–°ç»Ÿä¸€è·¯å¾„)
        - "/absolute/path/to/image.jpg" (ç»å¯¹è·¯å¾„)
        
    Returns:
        tuple: (base64_string, mime_type) æˆ– (None, None) å¦‚æœåŠ è½½å¤±è´¥
    """
    try:
        project_root = Path(__file__).parent.parent.parent

        image_path_str = image_path_or_filename
        if image_path_str.startswith('/'):
            # å¦‚æœè·¯å¾„ä»¥ / å¼€å¤´ï¼Œå…ˆç§»é™¤å®ƒï¼Œç„¶åå½“ä½œé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ç›¸å¯¹è·¯å¾„
            image_path_str = image_path_str.lstrip('/')

        # é¦–å…ˆå°è¯•ä»æ–°çš„ç»Ÿä¸€è·¯å¾„åŠ è½½
        if image_path_str.startswith('gym/test_images/'):
            image_path = project_root / image_path_str
            if image_path.exists():
                # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
                ext = image_path.suffix.lower()
                mime_type_map = {
                    '.jpg': 'image/jpeg',
                    '.jpeg': 'image/jpeg',
                    '.png': 'image/png',
                    '.gif': 'image/gif',
                    '.bmp': 'image/bmp',
                    '.webp': 'image/webp'
                }
                mime_type = mime_type_map.get(ext, 'image/jpeg')
                
                # è¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶ç¼–ç ä¸ºbase64
                with open(image_path, 'rb') as f:
                    image_data = f.read()
                    base64_string = base64.b64encode(image_data).decode('utf-8')
                    
                return base64_string, mime_type
            else:
                # æ–°è·¯å¾„ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›å¤±è´¥
                # æ³¨æ„ï¼šæ—§ç›®å½•çš„å›é€€é€»è¾‘å·²ç§»é™¤ï¼Œæ‰€æœ‰å›¾ç‰‡åº”ç»Ÿä¸€ä½¿ç”¨ gym/test_images/ è·¯å¾„
                print(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆæ–°è·¯å¾„ï¼‰: {image_path}")
                return None, None

        if '/' in image_path_str:
            # ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚ "failed_question_images/filename.jpg" æˆ– "sfe_images/..."ï¼‰
            image_path = project_root / image_path_str
        else:
            # ä»…æ–‡ä»¶åï¼ˆåœ¨imagesç›®å½•ä¸‹æŸ¥æ‰¾ï¼‰
            image_path = project_root / 'images' / image_path_str

        # å…¼å®¹è€æ•°æ®ï¼šéƒ¨åˆ†å›¾ç‰‡å®é™…æ”¾åœ¨ gym/ ä¸‹çš„å­ç›®å½•ä¸­
        if not image_path.exists():
            # å°è¯•åœ¨ gym/ ç›®å½•ä¸‹æŸ¥æ‰¾
            alt_path = project_root / "gym" / image_path_str
            if alt_path.exists():
                image_path = alt_path

        if not image_path.exists():
            print(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None, None
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
        ext = image_path.suffix.lower()
        mime_type_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.webp': 'image/webp'
        }
        mime_type = mime_type_map.get(ext, 'image/jpeg')
        
        # è¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶ç¼–ç ä¸ºbase64
        with open(image_path, 'rb') as f:
            image_data = f.read()
            base64_string = base64.b64encode(image_data).decode('utf-8')
            
        return base64_string, mime_type
        
    except Exception as e:
        print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {image_path_or_filename}: {e}")
        return None, None


def process_question_with_images(question_text):
    """å¤„ç†åŒ…å«å›¾ç‰‡çš„é—®é¢˜æ–‡æœ¬
    
    Args:
        question_text: åŸå§‹é—®é¢˜æ–‡æœ¬
        
    Returns:
        dict: åŒ…å«å¤„ç†åçš„é—®é¢˜å’Œå›¾ç‰‡ä¿¡æ¯çš„å­—å…¸
        {
            'text': str,  # æ¸…ç†åçš„é—®é¢˜æ–‡æœ¬
            'images': [   # å›¾ç‰‡ä¿¡æ¯åˆ—è¡¨
                {
                    'filename': str,
                    'base64': str,
                    'mime_type': str
                },
                ...
            ],
            'expected_image_count': int,
            'missing_images': [str]
        }
    """
    clean_text, image_filenames = extract_image_paths(question_text)
    
    result = {
        'text': clean_text,
        'images': [],
        'expected_image_count': len(image_filenames),
        'missing_images': []
    }
    
    # åŠ è½½æ‰€æœ‰å›¾ç‰‡
    for filename in image_filenames:
        base64_data, mime_type = load_image_as_base64(filename)
        if base64_data and mime_type:
            result['images'].append({
                'filename': filename,
                'base64': base64_data,
                'mime_type': mime_type
            })
        else:
            print(f"è·³è¿‡æ— æ³•åŠ è½½çš„å›¾ç‰‡: {filename}")
            result['missing_images'].append(filename)
    
    return result


def process_question_with_images_from_metadata(query_data):
    """å¤„ç†æŸ¥è¯¢æ•°æ®ï¼Œä» metadata ä¸­çš„ image_path åŠ è½½å›¾ç‰‡
    
    è¿™ä¸ªå‡½æ•°ä¸“é—¨ç”¨äºå¢å¼ºæµ‹è¯•ï¼Œä»åŸå§‹æ¡ˆä¾‹çš„ metadata.image_path ä¸­åŠ è½½å›¾ç‰‡
    
    Args:
        query_data: æµ‹è¯•æ¡ˆä¾‹æ•°æ®ï¼ŒåŒ…å« metadata.image_path
        
    Returns:
        dict: åŒ…å«å¤„ç†åçš„é—®é¢˜å’Œå›¾ç‰‡ä¿¡æ¯çš„å­—å…¸
        {
            'text': str,  # é—®é¢˜æ–‡æœ¬
            'images': [   # å›¾ç‰‡ä¿¡æ¯åˆ—è¡¨
                {
                    'path': str,
                    'base64': str,
                    'mime_type': str
                },
                ...
            ],
            'expected_image_count': int,
            'missing_images': [str]
        }
    """
    result = {
        'text': query_data.get('question', ''),
        'images': [],
        'expected_image_count': 0,
        'missing_images': []
    }
    
    # ä» metadata.image_path ä¸­è·å–å›¾ç‰‡è·¯å¾„
    image_paths = query_data.get('metadata', {}).get('image_path', [])
    if isinstance(image_paths, str):
        image_paths = [image_paths]
    elif not isinstance(image_paths, (list, tuple)):
        image_paths = []
    
    result['expected_image_count'] = len(image_paths)
    
    if image_paths:
        print(f"ğŸ“¸ å‘ç° {len(image_paths)} ä¸ªå›¾ç‰‡è·¯å¾„")
        for image_path in image_paths:
            print(f"   æ­£åœ¨å¤„ç†å›¾ç‰‡: {image_path}")
            base64_data, mime_type = load_image_as_base64(image_path)
            if base64_data and mime_type:
                result['images'].append({
                    'path': image_path,
                    'base64': base64_data,
                    'mime_type': mime_type
                })
                print(f"   âœ… æˆåŠŸåŠ è½½å›¾ç‰‡: {image_path}")
            else:
                print(f"   âŒ è·³è¿‡æ— æ³•åŠ è½½çš„å›¾ç‰‡: {image_path}")
                result['missing_images'].append(image_path)
    
    return result


def extract_golden_answer_template(query_data):
    """ä»golden_answerä¸­æå–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºè§„èŒƒå›ç­”æ¨¡æ¿
    
    æ”¯æŒå¤æ‚çš„åµŒå¥—ç»“æ„ï¼ŒåŒ…æ‹¬ï¼š
    - æ•°å€¼çŸ©é˜µ (å¦‚è´¨é‡çŸ©é˜µã€é›…å¯æ¯”çŸ©é˜µ)
    - æ–¹ç¨‹å­—ç¬¦ä¸²æ•°ç»„ (å¦‚çº¦æŸæ–¹ç¨‹ã€è¿åŠ¨æ–¹ç¨‹)
    - ç¬¦å·è¡¨è¾¾å¼çŸ©é˜µ (å¦‚ç¬¦å·é›…å¯æ¯”çŸ©é˜µ)
    - åµŒå¥—å­—å…¸ç»“æ„ (å¦‚è¯„ä¼°ç‚¹å‚æ•°)
    
    Args:
        query_data: åŒ…å«metadata.golden_answerçš„æ•°æ®å­—å…¸
        
    Returns:
        tuple: (template, original_data) æˆ– (None, None)
    """

    def create_template_recursive(obj, key_name=""):
        """é€’å½’åˆ›å»ºæ¨¡æ¿ï¼Œä¿ç•™åµŒå¥—ç»“æ„
        
        æ™ºèƒ½è¯†åˆ«ä¸åŒç±»å‹çš„æ•°æ®ç»“æ„ï¼š
        - æ•°å€¼çŸ©é˜µï¼šæ˜¾ç¤ºç»´åº¦ä¿¡æ¯
        - ç¬¦å·è¡¨è¾¾å¼çŸ©é˜µï¼šæ ‡æ³¨ä¸ºç¬¦å·è¡¨è¾¾å¼
        - æ–¹ç¨‹å­—ç¬¦ä¸²ï¼šæ ¹æ®ä¸Šä¸‹æ–‡æ ‡æ³¨
        - å‚æ•°å€¼ï¼šæ ¹æ®åç§°æ¨æ–­ç±»å‹
        
        Args:
            obj: è¦æ¨¡æ¿åŒ–çš„å¯¹è±¡
            key_name: å½“å‰å¯¹è±¡çš„é”®åï¼Œç”¨äºä¸Šä¸‹æ–‡åˆ¤æ–­
            
        Returns:
            æ¨¡æ¿åŒ–åçš„å¯¹è±¡ç»“æ„
        """
        if isinstance(obj, dict):
            template = {}
            for key, value in obj.items():
                template[key] = create_template_recursive(value, key)
            return template
        elif isinstance(obj, list):
            if len(obj) > 0:
                first_item = obj[0]
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å€¼çŸ©é˜µ/æ•°ç»„
                if isinstance(first_item, list):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å€¼çŸ©é˜µ
                    if all(isinstance(x, (int, float)) for x in first_item):
                        return f"[{len(obj)}x{len(first_item)} æ•°å€¼çŸ©é˜µ]"
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¦å·è¡¨è¾¾å¼çŸ©é˜µï¼ˆå¯èƒ½åŒ…å«å­—ç¬¦ä¸²å’Œæ•°å€¼ï¼‰
                    elif key_name == "symbolic":
                        return f"[{len(obj)}x{len(first_item)} ç¬¦å·è¡¨è¾¾å¼çŸ©é˜µ]"
                    else:
                        # å¯¹äºå…¶ä»–æ··åˆç±»å‹æ•°ç»„ï¼Œä¿ç•™ç»“æ„
                        return [create_template_recursive(first_item, f"{key_name}_item")]
                elif isinstance(first_item, (int, float)):
                    return f"[{len(obj)}ä¸ªæ•°å€¼çš„æ•°ç»„]"
                elif isinstance(first_item, str):
                    # ç‰¹æ®Šå¤„ç†çº¦æŸæ–¹ç¨‹ç­‰å­—ç¬¦ä¸²æ•°ç»„
                    if key_name in ["constraint_equations", "motion_equations"]:
                        return f"[{len(obj)}ä¸ªæ–¹ç¨‹å­—ç¬¦ä¸²]"
                    else:
                        return f"[{len(obj)}ä¸ªå­—ç¬¦ä¸²çš„æ•°ç»„]"
                else:
                    # å¯¹äºå¤æ‚å¯¹è±¡æ•°ç»„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå…ƒç´ çš„æ¨¡æ¿
                    return [create_template_recursive(first_item, f"{key_name}_item")]
            else:
                return []
        elif isinstance(obj, bool):
            return "[å¸ƒå°”å€¼]"
        elif isinstance(obj, (int, float)):
            # æ ¹æ®ä¸Šä¸‹æ–‡æä¾›æ›´å…·ä½“çš„æè¿°
            if key_name in ["theta", "beta", "S"]:
                return "[è§’åº¦/ä½ç½®å‚æ•°]"
            elif "matrix" in key_name.lower():
                return "[çŸ©é˜µå…ƒç´ ]"
            else:
                return "[æ•°å€¼]"
        elif isinstance(obj, str):
            # æ ¹æ®å†…å®¹æä¾›æ›´å…·ä½“çš„æè¿°
            if "=" in str(obj) and any(op in str(obj) for op in ["*", "+", "-", "**"]):
                return "[æ•°å­¦æ–¹ç¨‹å­—ç¬¦ä¸²]"
            elif key_name == "symbolic":
                return "[ç¬¦å·è¡¨è¾¾å¼]"
            else:
                return "[å­—ç¬¦ä¸²]"
        else:
            return "[å¾…å¡«å……]"

    try:
        golden_answers = query_data.get('metadata', {}).get('golden_answer', [])
        if golden_answers and len(golden_answers) > 0:
            first_answer = golden_answers[0]
            if isinstance(first_answer, dict):
                # é€’å½’åˆ›å»ºä¿ç•™ç»“æ„çš„æ¨¡æ¿
                template = create_template_recursive(first_answer, "root")
                return template, first_answer
        return None, None
    except Exception as e:
        print(f"æå–golden_answeræ¨¡æ¿å¤±è´¥: {e}")
        return None, None


def extract_augmented_answer_template(query_data):
    """ä»å¢å¼ºç‰ˆæµ‹è¯•æ¡ˆä¾‹ä¸­æå–final_answerä½œä¸ºè§„èŒƒå›ç­”æ¨¡æ¿
    
    ä¸“é—¨ç”¨äºå¤„ç†augmented_versionsä¸­çš„final_answerç»“æ„
    
    Args:
        query_data: åŒ…å«augmented_version_data.final_answerçš„æ•°æ®å­—å…¸
        
    Returns:
        tuple: (template, original_data) æˆ– (None, None)
    """
    def create_template_recursive(obj, key_name=""):
        """é€’å½’åˆ›å»ºæ¨¡æ¿ï¼Œä¿ç•™åµŒå¥—ç»“æ„"""
        if isinstance(obj, dict):
            template = {}
            for key, value in obj.items():
                template[key] = create_template_recursive(value, key)
            return template
        elif isinstance(obj, list):
            if len(obj) > 0:
                first_item = obj[0]
                if isinstance(first_item, list):
                    # æ•°å€¼çŸ©é˜µ
                    if all(isinstance(x, (int, float)) for x in first_item):
                        return f"[{len(obj)}x{len(first_item)} æ•°å€¼çŸ©é˜µ]"
                    else:
                        return [create_template_recursive(first_item, f"{key_name}_item")]
                elif isinstance(first_item, (int, float)):
                    return f"[{len(obj)}ä¸ªæ•°å€¼çš„æ•°ç»„]"
                elif isinstance(first_item, str):
                    return f"[{len(obj)}ä¸ªå­—ç¬¦ä¸²çš„æ•°ç»„]"
                else:
                    return [create_template_recursive(first_item, f"{key_name}_item")]
            else:
                return []
        elif isinstance(obj, bool):
            return "[å¸ƒå°”å€¼]"
        elif isinstance(obj, (int, float)):
            return "[æ•°å€¼]"
        elif isinstance(obj, str):
            return "[å­—ç¬¦ä¸²]"
        else:
            return "[å¾…å¡«å……]"

    try:
        # ä»å¢å¼ºç‰ˆæ•°æ®ä¸­è·å–final_answer
        augmented_data = query_data.get('augmented_version_data', {})
        final_answer = augmented_data.get('final_answer')
        
        if final_answer:
            if isinstance(final_answer, dict):
                # ä¸ºå¤æ‚ç»“æ„åˆ›å»ºæ¨¡æ¿
                template = create_template_recursive(final_answer, "root")
                return template, final_answer
            else:
                # å¯¹äºç®€å•ç±»å‹ï¼Œåˆ›å»ºåŸºæœ¬æ¨¡æ¿
                template = create_template_recursive(final_answer, "root")
                return template, final_answer
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°final_answerï¼Œå°è¯•ä»golden_answerä¸­è·å–
        return extract_golden_answer_template(query_data)
        
    except Exception as e:
        print(f"æå–å¢å¼ºç‰ˆç­”æ¡ˆæ¨¡æ¿å¤±è´¥: {e}")
        return None, None


def extract_refined_answer_template(query_data):
    """ä»ç²¾ç‚¼ç‰ˆæµ‹è¯•æ¡ˆä¾‹ä¸­æå–final_answerä½œä¸ºè§„èŒƒå›ç­”æ¨¡æ¿
    
    ä¸“é—¨ç”¨äºå¤„ç†refined_versionsä¸­çš„final_answerç»“æ„
    
    Args:
        query_data: åŒ…å«refined_version_data.final_answerçš„æ•°æ®å­—å…¸
        
    Returns:
        tuple: (template, original_data) æˆ– (None, None)
    """
    def create_template_recursive(obj, key_name=""):
        """é€’å½’åˆ›å»ºæ¨¡æ¿ï¼Œä¿ç•™åµŒå¥—ç»“æ„"""
        if isinstance(obj, dict):
            template = {}
            for key, value in obj.items():
                template[key] = create_template_recursive(value, key)
            return template
        elif isinstance(obj, list):
            if len(obj) > 0:
                first_item = obj[0]
                if isinstance(first_item, list):
                    # æ•°å€¼çŸ©é˜µ
                    if all(isinstance(x, (int, float)) for x in first_item):
                        return f"[{len(obj)}x{len(first_item)} æ•°å€¼çŸ©é˜µ]"
                    else:
                        return [create_template_recursive(first_item, f"{key_name}_item")]
                elif isinstance(first_item, (int, float)):
                    return f"[{len(obj)}ä¸ªæ•°å€¼çš„æ•°ç»„]"
                elif isinstance(first_item, str):
                    return f"[{len(obj)}ä¸ªå­—ç¬¦ä¸²çš„æ•°ç»„]"
                else:
                    return [create_template_recursive(first_item, f"{key_name}_item")]
            else:
                return []
        elif isinstance(obj, bool):
            return "[å¸ƒå°”å€¼]"
        elif isinstance(obj, (int, float)):
            return "[æ•°å€¼]"
        elif isinstance(obj, str):
            return "[å­—ç¬¦ä¸²]"
        else:
            return "[å¾…å¡«å……]"

    try:
        # ä»ç²¾ç‚¼ç‰ˆæ•°æ®ä¸­è·å–final_answer
        refined_data = query_data.get('refined_version_data', {})
        final_answer = refined_data.get('final_answer')
        
        if final_answer:
            if isinstance(final_answer, dict):
                # ä¸ºå¤æ‚ç»“æ„åˆ›å»ºæ¨¡æ¿
                template = create_template_recursive(final_answer, "root")
                return template, final_answer
            else:
                # å¯¹äºç®€å•ç±»å‹ï¼Œåˆ›å»ºåŸºæœ¬æ¨¡æ¿
                template = create_template_recursive(final_answer, "root")
                return template, final_answer
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°final_answerï¼Œå°è¯•ä»golden_answerä¸­è·å–
        return extract_golden_answer_template(query_data)
        
    except Exception as e:
        print(f"æå–ç²¾ç‚¼ç‰ˆç­”æ¡ˆæ¨¡æ¿å¤±è´¥: {e}")
        return None, None


def extract_structured_answer_from_response(response_content):
    """ä»æ¨¡å‹å›ç­”ä¸­æå–ç»“æ„åŒ–çš„JSONç­”æ¡ˆ"""
    if not response_content:
        return None

    try:
        # é¢„å¤„ç†ï¼šç§»é™¤LaTeXåŒ…è£…å’Œå…¶ä»–æ ¼å¼ï¼ˆä¸ä¸¢å†…å®¹ï¼‰
        processed_content = _preprocess_response_content(response_content)

        candidates = []  # æ”¶é›†æ‰€æœ‰å¯è§£æJSONå€™é€‰

        def _try_parse_and_collect(json_str: str, source_tag: str):
            if not json_str:
                return
            try:
                # å…ˆå°è¯•ç›´æ¥è§£æï¼Œä¸åšæ¸…æ´—ï¼Œé¿å…ç ´åæœ¬å°±åˆæ³•çš„JSON
                try:
                    parsed = json.loads(json_str)
                    cleaned_len_ref = len(json_str)
                except json.JSONDecodeError:
                    cleaned_json = _clean_json_string(json_str)
                    parsed = json.loads(cleaned_json)
                    cleaned_len_ref = len(cleaned_json)
                # ä¸ºå€™é€‰æ‰“åˆ†ï¼šä¼˜å…ˆå­—å…¸ï¼Œå…¶æ¬¡åˆ—è¡¨ï¼›æ›´é•¿çš„å­—ç¬¦ä¸²ã€æ›´å¤šé”®ã€åµŒå¥—æ›´æ·±è€…ä¼˜å…ˆ
                score = 0
                try:
                    score += cleaned_len_ref  # é•¿åº¦
                except Exception:
                    pass
                if isinstance(parsed, dict):
                    score += 5000
                    try:
                        score += len(parsed) * 50
                    except Exception:
                        pass
                elif isinstance(parsed, list):
                    score += 3000
                    try:
                        score += len(parsed) * 10
                    except Exception:
                        pass
                candidates.append((score, parsed, source_tag))
            except json.JSONDecodeError:
                pass

        # æ–¹æ³•1ï¼šä¼˜å…ˆè§£æä»£ç å—ä¸­çš„å®Œæ•´å†…å®¹ï¼ˆè€Œä¸æ˜¯ç¬¬ä¸€ä¸ªæœ€å°èŠ±æ‹¬å·ï¼‰
        codeblock_pattern = r"```(?:json)?\s*([\s\S]*?)\s*```"
        code_blocks = re.findall(codeblock_pattern, processed_content, re.IGNORECASE)
        for block in code_blocks:
            # ç›´æ¥å°è¯•æŠŠæ•´ä¸ªä»£ç å—ä½œä¸ºJSONè§£æ
            _try_parse_and_collect(block, 'codeblock_full')
            # å¦‚æœå¤±è´¥ï¼Œä»ä»£ç å—å†…éƒ¨æå–å¯èƒ½çš„JSONå¯¹è±¡ï¼ˆæŒ‰é…å¯¹èŠ±æ‹¬å·ï¼‰
            potential_in_block = _extract_potential_json_objects(block)
            potential_in_block.sort(key=len, reverse=True)
            for js in potential_in_block:
                _try_parse_and_collect(js, 'codeblock_potential')

        # æ–¹æ³•2ï¼šLaTeX boxed åŒ…è£¹
        boxed_pattern = r'\$\\boxed\{([\s\S]*?)\}\$'
        boxed_matches = re.findall(boxed_pattern, processed_content)
        for match in boxed_matches:
            cleaned_match = _clean_latex_json(match)
            _try_parse_and_collect(cleaned_match, 'latex_boxed')
            # å†ä»å†…éƒ¨æå–å¯èƒ½çš„JSON
            potential_in_box = _extract_potential_json_objects(cleaned_match)
            potential_in_box.sort(key=len, reverse=True)
            for js in potential_in_box:
                _try_parse_and_collect(js, 'latex_potential')

        # æ–¹æ³•3ï¼šä»å…¨æ–‡ä¸­æŒ‰èŠ±æ‹¬å·é…å¯¹æå–å€™é€‰
        potential_jsons = _extract_potential_json_objects(processed_content)
        potential_jsons.sort(key=len, reverse=True)
        for json_str in potential_jsons:
            _try_parse_and_collect(json_str, 'fulltext_potential')

        # é€‰æ‹©æœ€ä½³å€™é€‰
        if candidates:
            candidates.sort(key=lambda x: x[0], reverse=True)
            raw_result = candidates[0][1]
            # å¯¹æå–çš„ç­”æ¡ˆè¿›è¡Œåå¤„ç†ï¼Œä¿®å¤å¸¸è§é—®é¢˜
            return _post_process_extracted_answer(raw_result)

        return None

    except Exception as e:
        print(f"æå–ç»“æ„åŒ–ç­”æ¡ˆå¤±è´¥: {e}")
        return None


def _post_process_extracted_answer(answer):
    """å¯¹æå–çš„ç­”æ¡ˆè¿›è¡Œåå¤„ç†ï¼Œä¿®å¤å¸¸è§çš„ç»“æ„å’Œç±»å‹é—®é¢˜"""
    if not isinstance(answer, dict):
        return answer

    # ä¿®å¤ç¼ºå¤±çš„é¡¶å±‚é”®é—®é¢˜
    # å¦‚æœç­”æ¡ˆçœ‹èµ·æ¥åƒæ˜¯ç›´æ¥çš„å†…å®¹è€Œä¸æ˜¯åŒ…è£…åœ¨é¡¶å±‚é”®ä¸­ï¼Œå°è¯•åŒ…è£…å®ƒ
    processed_answer = _fix_missing_top_level_key(answer)

    # ä¿®å¤å­—ç¬¦ä¸²æ•°å€¼å’Œå¸ƒå°”å€¼é—®é¢˜
    processed_answer = _normalize_data_types(processed_answer)

    return processed_answer


def _fix_missing_top_level_key(answer):
    """ä¿®å¤ç¼ºå¤±é¡¶å±‚é”®çš„é—®é¢˜

    æŸäº›æ¨¡å‹å›ç­”å¯èƒ½ç¼ºå°‘é¢„æœŸçš„é¡¶å±‚é”®ï¼Œå¦‚"å…³é”®é‡"ç­‰
    """
    if not isinstance(answer, dict):
        return answer

    # æ£€æµ‹æ˜¯å¦ç¼ºå°‘å¸¸è§çš„é¡¶å±‚é”®
    common_top_keys = ["å…³é”®é‡", "answer", "result", "solution"]

    # å¦‚æœç­”æ¡ˆå·²ç»åŒ…å«è¿™äº›é¡¶å±‚é”®ä¹‹ä¸€ï¼Œåˆ™ä¸éœ€è¦ä¿®å¤
    for key in common_top_keys:
        if key in answer:
            return answer

    # æ£€æŸ¥æ˜¯å¦ç­”æ¡ˆå†…å®¹ç›´æ¥åŒ…å«äº†é¢„æœŸç»“æ„çš„å†…éƒ¨é”®
    expected_inner_keys = ["è§£æç»“æœ", "ä»£å…¥æ•°å€¼", "å››çŠ¶æ€(P,V,T)", "åŠŸä¸çƒ­(å–è¿‡ç¨‹æ–¹å‘ä¸ºæ­£)", "ä¸€è‡´æ€§æ ¸æŸ¥æ¸…å•"]

    # å¦‚æœå‘ç°å†…éƒ¨é”®ï¼Œè¯´æ˜å¯èƒ½ç¼ºå°‘"å…³é”®é‡"åŒ…è£…
    found_inner_keys = sum(1 for key in expected_inner_keys if key in answer)
    if found_inner_keys >= 2:  # å¦‚æœå‘ç°2ä¸ªæˆ–æ›´å¤šå†…éƒ¨é”®ï¼Œè®¤ä¸ºéœ€è¦åŒ…è£…
        return {"å…³é”®é‡": answer}

    return answer


def _normalize_data_types(obj):
    """é€’å½’åœ°è§„èŒƒåŒ–æ•°æ®ç±»å‹ï¼Œå°†å­—ç¬¦ä¸²æ•°å€¼è½¬æ¢ä¸ºæ•°å€¼ï¼Œå­—ç¬¦ä¸²å¸ƒå°”å€¼è½¬æ¢ä¸ºå¸ƒå°”å€¼"""
    if isinstance(obj, dict):
        return {k: _normalize_data_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [_normalize_data_types(item) for item in obj]
    elif isinstance(obj, str):
        # å°è¯•è½¬æ¢å­—ç¬¦ä¸²æ•°å€¼
        normalized = _try_convert_string_to_number_or_bool(obj)
        return normalized
    else:
        return obj


def _try_convert_string_to_number_or_bool(value):
    """å°è¯•å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆé€‚çš„æ•°å€¼æˆ–å¸ƒå°”ç±»å‹"""
    if not isinstance(value, str):
        return value

    value_stripped = value.strip()

    # è½¬æ¢å¸ƒå°”å€¼
    if value_stripped.lower() == 'true':
        return True
    elif value_stripped.lower() == 'false':
        return False

    # è½¬æ¢æ•°å€¼
    try:
        # å¤„ç†ç§‘å­¦è®°æ•°æ³•ï¼Œå¦‚ "2.494e-2"
        if 'e' in value_stripped.lower():
            return float(value_stripped)
        # å¤„ç†æ•´æ•°
        if '.' not in value_stripped:
            # ä½†è¦æ’é™¤æ˜æ˜¾ä¸æ˜¯æ•°å­—çš„å­—ç¬¦ä¸²
            if value_stripped.isdigit() or (value_stripped.startswith('-') and value_stripped[1:].isdigit()):
                return int(value_stripped)
        # å¤„ç†æµ®ç‚¹æ•°
        else:
            return float(value_stripped)
    except (ValueError, TypeError):
        pass

    # å¦‚æœæ— æ³•è½¬æ¢ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
    return value


def _preprocess_response_content(content):
    """é¢„å¤„ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä¸€äº›å¸¸è§çš„æ ¼å¼åŒ…è£…ä½†ä¿ç•™JSONå†…å®¹"""
    if not content:
        return content
    
    # ä¸ç§»é™¤ä»»ä½•å®é™…å†…å®¹ï¼Œåªæ˜¯æ¸…ç†ï¼Œä¿ç•™å®Œæ•´çš„å“åº”
    # è¿™æ ·æˆ‘ä»¬å¯ä»¥åœ¨å„ä¸ªæ–¹æ³•ä¸­å¤„ç†ä¸åŒçš„æ ¼å¼
    return content.strip()


def _clean_latex_json(latex_json):
    """æ¸…ç†LaTeXæ ¼å¼çš„JSONå­—ç¬¦ä¸²"""
    if not latex_json:
        return latex_json
    
    # ç§»é™¤LaTeXè½¬ä¹‰å­—ç¬¦
    cleaned = latex_json.replace('\\{', '{').replace('\\}', '}')
    cleaned = cleaned.replace('\\"', '"')
    cleaned = cleaned.replace('\\\\', '\\')
    
    return cleaned


def _clean_json_string(json_str):
    """æ¸…ç†JSONå­—ç¬¦ä¸²ï¼Œç§»é™¤å¤šä½™çš„ç©ºç™½å’Œæ ¼å¼å­—ç¬¦ï¼Œå¹¶å¤„ç†æ— æ•ˆçš„è¡¨è¾¾å¼"""
    if not json_str:
        return json_str
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦
    cleaned = json_str.strip()
    
    # ç§»é™¤å¯èƒ½çš„å¼•å·åŒ…è£…
    if cleaned.startswith('"') and cleaned.endswith('"'):
        cleaned = cleaned[1:-1]
    
    # å¤„ç†JavaScriptè¡¨è¾¾å¼ï¼ˆå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼‰
    cleaned = _fix_javascript_expressions(cleaned)
    
    return cleaned


def _fix_javascript_expressions(json_str):
    """ä¿®å¤JSONä¸­çš„JavaScriptè¡¨è¾¾å¼ï¼Œå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
    import re
    
    # åŒ¹é…å¸¸è§çš„æ•°å­¦è¡¨è¾¾å¼æ¨¡å¼ï¼ˆå¦‚ 0.5 * p_0ï¼‰
    # æŸ¥æ‰¾åœ¨JSONå€¼ä½ç½®çš„è¡¨è¾¾å¼ï¼ˆå†’å·åé¢ï¼Œé€—å·å‰é¢æˆ–æ‹¬å·å‰é¢ï¼‰
    patterns = [
        # æ•°å­—ä¹˜æ³•è¡¨è¾¾å¼ (å¦‚: 0.5 * p_0)
        (r':\s*([0-9.]+\s*\*\s*[a-zA-Z_][a-zA-Z0-9_]*)', r': "\1"'),
        # å˜é‡è¡¨è¾¾å¼ (å¦‚: p_0)  
        (r':\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*([,}])', r': "\1"\2'),
        # å¤æ‚æ•°å­¦è¡¨è¾¾å¼
        (r':\s*([^",{}[\]]+\s*[*/+-]\s*[^",{}[\]]+)', r': "\1"'),
    ]
    
    for pattern, replacement in patterns:
        json_str = re.sub(pattern, replacement, json_str)
    
    return json_str


def _extract_potential_json_objects(content):
    """ä»å†…å®¹ä¸­æå–æ½œåœ¨çš„JSONå¯¹è±¡"""
    potential_jsons = []

    # Find all { } pairs that could be complete JSON objects
    start_positions = [i for i, char in enumerate(content) if char == '{']

    for start_pos in start_positions:
        brace_count = 0
        for i in range(start_pos, len(content)):
            if content[i] == '{':
                brace_count += 1
            elif content[i] == '}':
                brace_count -= 1
                if brace_count == 0:
                    candidate = content[start_pos:i+1]
                    # ç®€å•è¿‡æ»¤ï¼šé¿å…æŠŠæ˜æ˜¾çš„ä»£ç ç‰‡æ®µï¼ˆå¦‚ function(){}, if(){}) å½“ä½œJSON
                    if 'function' in candidate or '=>{' in candidate:
                        break
                    potential_jsons.append(candidate)
                    break

        # å¤„ç†ä¸å®Œæ•´çš„JSONï¼ˆæ²¡æœ‰åŒ¹é…çš„ç»“æŸèŠ±æ‹¬å·ï¼‰
        if brace_count > 0:
            incomplete_json = content[start_pos:]
            # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON
            repaired_json = _try_repair_incomplete_json(incomplete_json)
            if repaired_json:
                potential_jsons.append(repaired_json)

    return potential_jsons


def _try_repair_incomplete_json(incomplete_json):
    """å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSONå­—ç¬¦ä¸²"""
    try:
        import re
        import json

        # ç§»é™¤æœ«å°¾çš„ä¸å®Œæ•´å†…å®¹ï¼ˆå¦‚ "ç­‰ç­‰", "..."ç­‰ï¼‰
        cleaned = re.sub(r'\s*(ç­‰ç­‰|\.\.\.|\.\.\.|â€¦).*$', '', incomplete_json, flags=re.DOTALL)

        # å¤„ç†ä¸å®Œæ•´çš„é”®å€¼å¯¹ï¼Œç‰¹åˆ«æ˜¯ç±»ä¼¼ "key":  çš„æƒ…å†µ
        # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ä¸å®Œæ•´çš„é”®å€¼å¯¹
        lines = cleaned.split('\n')
        valid_content = []

        for line in lines:
            stripped = line.strip()
            if not stripped:
                valid_content.append(line)
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸å®Œæ•´çš„é”®å€¼å¯¹
            if ':' in stripped:
                # å¦‚æœè¡Œä»¥ : ç»“å°¾æˆ–è€…å€¼éƒ¨åˆ†ä¸ºç©º/ä¸å®Œæ•´ï¼Œç§»é™¤è¿™è¡Œ
                if re.search(r':\s*$', stripped) or re.search(r':\s*"[^"]*$', stripped):
                    # ç§»é™¤è¿™ä¸ªä¸å®Œæ•´çš„é”®å€¼å¯¹ï¼Œä½†è¦æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰é€—å·éœ€è¦ç§»é™¤
                    if valid_content and valid_content[-1].strip().endswith(','):
                        # ç§»é™¤å‰ä¸€è¡Œæœ«å°¾çš„é€—å·
                        valid_content[-1] = valid_content[-1].rstrip().rstrip(',')
                    break

            valid_content.append(line)

        # é‡æ–°ç»„åˆå†…å®¹
        repaired = '\n'.join(valid_content).strip()

        # ç§»é™¤æœ«å°¾å¯èƒ½çš„å¤šä½™é€—å·
        repaired = re.sub(r',(\s*[\]}])', r'\1', repaired)
        repaired = re.sub(r',\s*$', '', repaired)

        # è®¡ç®—ç¼ºå¤±çš„é—­åˆæ‹¬å·æ•°é‡
        brace_count = repaired.count('{') - repaired.count('}')
        bracket_count = repaired.count('[') - repaired.count(']')

        # æ·»åŠ ç¼ºå¤±çš„é—­åˆæ‹¬å·
        repaired += ']' * bracket_count + '}' * brace_count

        # å°è¯•è§£æä¿®å¤åçš„JSON
        parsed = json.loads(repaired)
        return repaired

    except Exception as e:
        # å¦‚æœä¿®å¤å¤±è´¥ï¼Œå°è¯•å¦ä¸€ç§ç­–ç•¥ï¼šæ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡/æ•°ç»„
        try:
            import re
            import json

            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æˆªæ–­ç‚¹
            lines = incomplete_json.split('\n')
            for i in range(len(lines) - 1, -1, -1):
                truncated = '\n'.join(lines[:i+1])

                # å°è¯•å¹³è¡¡æ‹¬å·
                brace_count = truncated.count('{') - truncated.count('}')
                bracket_count = truncated.count('[') - truncated.count(']')

                if brace_count >= 0 and bracket_count >= 0:
                    # ç§»é™¤æœ«å°¾çš„é€—å·
                    truncated = re.sub(r',\s*$', '', truncated.strip())
                    test_json = truncated + ']' * bracket_count + '}' * brace_count

                    try:
                        json.loads(test_json)
                        return test_json
                    except:
                        continue

            return None

        except Exception:
            return None
