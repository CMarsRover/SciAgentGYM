"""
æ ¸å¿ƒè¯„åˆ†ç®—æ³•æ¨¡å—

è¿™ä¸ªæ¨¡å—åŒ…å«ï¼š
- ç­”æ¡ˆæå–ï¼šextract_boxed_answer ä»æ¨¡å‹å›ç­”ä¸­æŠ½å– \\boxed{} å†…çš„æœ€ç»ˆç­”æ¡ˆ
- ç­”æ¡ˆåˆ¤æ–­ï¼šis_answer_correct åŸºäº LLM çš„å¯¹/é”™åˆ¤é¢˜æ¥å£
- è¯„åˆ†ç®—æ³•ï¼šcalculate_answer_score ç­‰æ ¸å¿ƒè¯„åˆ†å‡½æ•°

å®ç°é«˜å†…èšä½è€¦åˆçš„è®¾è®¡åŸåˆ™ã€‚
"""
import json
import math
import re
import sys
import os
from pathlib import Path
from typing import Dict, Tuple, Any, Iterable, List, Optional

# Add project root to path so we can import modules
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from gym.config.dataset_config import get_trace_root


# ========== ç­”æ¡ˆæå–ä¸åˆ¤æ–­ ==========

def _extract_balanced_braces(text: str, start_pos: int) -> Optional[str]:
    """
    ä»ç»™å®šä½ç½®å¼€å§‹ï¼Œæå–ä¸ç¬¬ä¸€ä¸ª '{' åŒ¹é…çš„æˆå¯¹å¤§æ‹¬å·ä¸­çš„å†…å®¹ã€‚
    ä½¿ç”¨æ‰‹åŠ¨æ ˆåŒ¹é…ç®—æ³•ï¼Œæ”¯æŒä»»æ„åµŒå¥—çº§åˆ«çš„å¤§æ‹¬å·ã€‚
    """
    if not text or start_pos < 0 or start_pos >= len(text):
        return None

    if text[start_pos] != "{":
        return None

    stack = 0
    result_chars = []

    for idx in range(start_pos, len(text)):
        ch = text[idx]
        if ch == "{":
            stack += 1
            # ç¬¬ä¸€ä¸ªå·¦æ‹¬å·æœ¬èº«ä¸è®¡å…¥ç»“æœï¼Œåªè®°å½•å†…éƒ¨å†…å®¹
            if stack > 1:
                result_chars.append(ch)
        elif ch == "}":
            stack -= 1
            if stack == 0:
                # åŒ¹é…ç»“æŸ
                return "".join(result_chars)
            elif stack < 0:
                # ä¸æ­£å¸¸çš„æ‹¬å·ç»“æ„
                return None
            else:
                result_chars.append(ch)
        else:
            if stack >= 1:
                result_chars.append(ch)

    # æ²¡æœ‰æ­£å¸¸é—­åˆ
    return None


def extract_boxed_answer(response_content: Optional[str]) -> Optional[str]:
    """ä»æ¨¡å‹å›ç­”ä¸­æå– \\boxed{} ä¸­çš„å†…å®¹ã€‚

    ä½¿ç”¨æ‰‹åŠ¨æ‹¬å·åŒ¹é…ç®—æ³•ï¼Œæ”¯æŒä»»æ„åµŒå¥—çº§åˆ«çš„å¤§æ‹¬å·ã€‚

    Args:
        response_content: æ¨¡å‹çš„å›ç­”æ–‡æœ¬

    Returns:
        æå–çš„ boxed ä¸­çš„å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å› None
    """
    if not response_content or not isinstance(response_content, str):
        return None

    try:
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„ boxed å¼€å§‹ä½ç½®
        boxed_patterns = [
            r"\\boxed\{",
            r"\$\\boxed\{",
            r"boxed\{",
        ]

        all_matches = []
        for pattern in boxed_patterns:
            for match in re.finditer(pattern, response_content):
                # match.end() æŒ‡å‘ '{' åçš„ç¬¬ä¸€ä¸ªå­—ç¬¦ï¼Œå› æ­¤å‡ 1 å›åˆ° '{'
                start_pos = match.end() - 1
                content = _extract_balanced_braces(response_content, start_pos)
                if content is not None:
                    all_matches.append(content)

        if all_matches:
            # è¿”å›æœ€åä¸€ä¸ªåŒ¹é…ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç­”æ¡ˆï¼‰
            answer = all_matches[-1].strip()
            print(f"ğŸ¯ æå–åˆ°boxedç­”æ¡ˆ: {answer}")
            return answer

        print("âš ï¸ æœªæ‰¾åˆ°boxedæ ¼å¼çš„ç­”æ¡ˆ")
        return None

    except Exception as e:
        print(f"æå–boxedç­”æ¡ˆå¤±è´¥: {e}")
        return None


def is_answer_correct(question_text, model_answer, standard_answer, unique_id):
    """åˆ¤æ–­æ¨¡å‹çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®

    è¯„åˆ¤è¦æ±‚ï¼š
    1. å¿½ç•¥ç­”æ¡ˆä¸­çš„æ ¼å¼å·®å¼‚ã€‚
    2. å¿½ç•¥æ— å…³çš„å‰ç¼€æˆ–æ–‡å­—ä¿®é¥°ã€‚
    3. å¦‚æœæ ‡å‡†ç­”æ¡ˆæ˜¯ä¸€ä¸ªè¡¨è¾¾å¼æˆ–æ•°å€¼ï¼Œåªè¦æ¨¡å‹ç­”æ¡ˆåœ¨é€»è¾‘ã€è®¡ç®—æˆ–æ•°å€¼ä¸Šç­‰ä»·ï¼Œä¹Ÿè§†ä¸ºæ­£ç¡®ã€‚
    4. è‹¥æ¨¡å‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆ**æ ¸å¿ƒå†…å®¹ä¸€è‡´**ï¼Œåˆ™åˆ¤æ–­ä¸º"æ­£ç¡®"ã€‚
    """
    prompt = f"""è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ã€ä¸€ä¸ªæ ‡å‡†ç­”æ¡ˆï¼Œä»¥åŠä¸€ä¸ªç”±AIæ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆã€‚è¯·ä½ åˆ¤æ–­AIæ¨¡å‹çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚
    è¯„åˆ¤è¦æ±‚ï¼š
    1. å¿½ç•¥ç­”æ¡ˆä¸­çš„æ ¼å¼å·®å¼‚ã€‚
    2. å¿½ç•¥æ— å…³çš„å‰ç¼€æˆ–æ–‡å­—ä¿®é¥°ã€‚
    3. å¦‚æœæ ‡å‡†ç­”æ¡ˆæ˜¯ä¸€ä¸ªè¡¨è¾¾å¼æˆ–æ•°å€¼ï¼Œåªè¦æ¨¡å‹ç­”æ¡ˆåœ¨é€»è¾‘ã€è®¡ç®—æˆ–æ•°å€¼ä¸Šç­‰ä»·ï¼Œä¹Ÿè§†ä¸ºæ­£ç¡®ã€‚
    4. è‹¥æ¨¡å‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆ**æ ¸å¿ƒå†…å®¹ä¸€è‡´**ï¼Œåˆ™åˆ¤æ–­ä¸º"æ­£ç¡®"ã€‚

    è¯·åªè¾“å‡ºï¼š`æ­£ç¡®` æˆ– `é”™è¯¯`ã€‚

    ---
    é—®é¢˜ï¼š
    {question_text}
    ---
    æ ‡å‡†ç­”æ¡ˆï¼š
    {standard_answer}
    ---
    AIæ¨¡å‹çš„ç­”æ¡ˆï¼š
    {model_answer}
    ---
    """
    
    try:
        # ä½¿ç”¨æœ¬é¡¹ç›® gym/config/config.py ä¸­å®šä¹‰çš„åˆ¤é¢˜æ¨¡å‹
        from gym.config.config import JUDGE_MODEL
        from gym.agent import get_client

        evaluation_model = JUDGE_MODEL  # é€šå¸¸ä¸º "gpt-4.1"

        client = get_client(evaluation_model)
        response = client.chat_completions_create(
            messages=[{"role": "user", "content": prompt}],
            max_tokens=5,
        )

        result = response.choices[0].message.content.strip()
        is_correct = result == "æ­£ç¡®"
        
        print(f"  åˆ¤æ–­ç»“æœ: {result} ({'âœ…' if is_correct else 'âŒ'})")
        return is_correct
        
    except Exception as e:
        print(f"  âŒ ç­”æ¡ˆåˆ¤æ–­å¤±è´¥: {e}")
        raise


# ========== æ ¸å¿ƒè¯„åˆ†ç®—æ³• ==========


def _count_fields_recursive(obj, path=""):
    """é€’å½’è®¡ç®—é‡‘æ ‡å‡†ä¸­çš„å¶å­å­—æ®µæ•°é‡"""
    if isinstance(obj, dict):
        count = 0
        for key, value in obj.items():
            key_path = f"{path}.{key}" if path else key
            if isinstance(value, (dict, list)):
                count += _count_fields_recursive(value, key_path)
            else:
                count += 1
        return count
    if isinstance(obj, list):
        count = 0
        for i, item in enumerate(obj):
            item_path = f"{path}[{i}]" if path else f"[{i}]"
            if isinstance(item, (dict, list)):
                count += _count_fields_recursive(item, item_path)
            else:
                count += 1
        return count
    return 1


def _iter_expected_leaf_paths(expected, path=""):
    """æŒ‰é¡ºåºéå†é‡‘æ ‡å‡†ä¸­çš„å¶å­å­—æ®µè·¯å¾„"""
    if isinstance(expected, dict):
        for key, value in expected.items():
            key_path = f"{path}.{key}" if path else key
            yield from _iter_expected_leaf_paths(value, key_path)
    elif isinstance(expected, list):
        for idx, item in enumerate(expected):
            key_path = f"{path}[{idx}]" if path else f"[{idx}]"
            yield from _iter_expected_leaf_paths(item, key_path)
    else:
        yield path


def _count_matches_from_details(details: Dict[str, Dict]) -> int:
    """ä»è¯„æµ‹ç»†èŠ‚ä¸­ç»Ÿè®¡åŒ¹é…æ•°é‡"""
    return sum(1 for detail in details.values() if detail.get("status") == "match")


def build_match_sequence(golden_standard: Dict, field_details: Dict[str, Dict]) -> List[bool]:
    """
    æ„å»ºä¸é‡‘æ ‡å‡†é¡ºåºä¸€è‡´çš„åŒ¹é…å¸ƒå°”åºåˆ—
    """
    sequence: List[bool] = []
    for path in _iter_expected_leaf_paths(golden_standard):
        detail = field_details.get(path)
        sequence.append(bool(detail and detail.get("status") == "match"))
    return sequence


def compute_segment_scores_from_details(
    golden_standard: Dict,
    field_details: Dict[str, Dict],
    segments: Iterable[int] = (25, 50, 75, 100),
) -> Dict[str, float]:
    """
    æ ¹æ®åŒ¹é…åºåˆ—è®¡ç®—ä¸åŒè¦†ç›–èŒƒå›´çš„åˆ†æ•°ï¼ˆä¾‹å¦‚å‰25%ã€50%ã€75%ã€100%ï¼‰
    """
    match_sequence = build_match_sequence(golden_standard, field_details)
    total = len(match_sequence)
    if total == 0:
        return {}

    segment_scores: Dict[str, float] = {}
    for segment in segments:
        if segment <= 0:
            continue
        coverage_count = min(total, max(1, math.ceil(total * (segment / 100))))
        covered_matches = sum(match_sequence[:coverage_count])
        segment_scores[f"0_{segment}"] = covered_matches / coverage_count

    return segment_scores


def is_answer_correct_with_llm(question_text, model_answer, standard_answer, unique_id):
    """ä½¿ç”¨LLMåˆ¤æ–­æ¨¡å‹ç­”æ¡ˆæ˜¯å¦æ­£ç¡®"""
    prompt = f"""è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ã€ä¸€ä¸ªæ ‡å‡†ç­”æ¡ˆï¼Œä»¥åŠä¸€ä¸ªç”±AIæ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆã€‚è¯·ä½ åˆ¤æ–­AIæ¨¡å‹çš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚
    è¯·ä¸¥æ ¼æ ¹æ®æ ‡å‡†ç­”æ¡ˆè¿›è¡Œè¯„åˆ¤ã€‚å¦‚æœAIçš„ç­”æ¡ˆåœ¨é€»è¾‘ã€è®¡ç®—ã€æ¦‚å¿µä¸Šä¸æ ‡å‡†ç­”æ¡ˆä¸€è‡´ï¼Œå³ä¾¿æªè¾ä¸åŒï¼Œä¹Ÿåº”åˆ¤æ–­ä¸ºæ­£ç¡®ã€‚
    è¯·åªå›ç­” 'æ­£ç¡®' æˆ– 'é”™è¯¯'ã€‚

    ---
    é—®é¢˜ï¼š
    {question_text}
    ---
    æ ‡å‡†ç­”æ¡ˆï¼š
    {standard_answer}
    ---
    AIæ¨¡å‹çš„ç­”æ¡ˆï¼š
    {model_answer}
    ---
    """

    try:
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­å®šä¹‰çš„æ¨¡å‹è¿›è¡Œè¯„åˆ¤
        from gym.config.config import JUDGE_MODEL
        from gym.utils.client_manager import get_client

        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ¨¡å‹
        evaluation_model = JUDGE_MODEL

        payload = {
            "model": evaluation_model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 5
        }

        client = get_client(evaluation_model)

        response = client.chat_completions_create(
            messages=payload["messages"],
            max_tokens=payload["max_tokens"]
        )

        result = response.choices[0].message.content.strip()
        is_correct = result == "æ­£ç¡®"

        print(f"  LLMåˆ¤æ–­ç»“æœ: {result} ({'âœ…' if is_correct else 'âŒ'})")
        return is_correct

    except Exception as e:
        print(f"  âŒ LLMç­”æ¡ˆåˆ¤æ–­å¤±è´¥: {e}")
        return False


def evaluate_pass_at_k_results(
    model_name: Optional[str] = None,
    use_tools: Optional[Any] = None,
    k: Optional[int] = None,
    trace_dir: Optional[str] = None,
) -> Dict[str, Any]:
    """è¯„ä¼° pass@k æ±‡æ€»æ–‡ä»¶ï¼Œç»Ÿè®¡æœ€ä½³ç»“æœå‡†ç¡®ç‡ã€‚"""

    from gym.config.config import PASS_AT_K

    if k is None:
        k = PASS_AT_K

    if trace_dir is not None:
        pass_root = Path(trace_dir)
    else:
        base_root = get_trace_root()
        pass_root = base_root / f"pass@{k}"
        if model_name:
            pass_root = pass_root / model_name
            if use_tools == 'with_all_tools':
                pass_root = pass_root / 'with_all_tools'
            elif use_tools is True:
                pass_root = pass_root / 'with_tools'
            elif use_tools is False:
                pass_root = pass_root / 'without_tools'

    if not pass_root.exists():
        print(f"âŒ pass@{k} ç›®å½•ä¸å­˜åœ¨: {pass_root}")
        return {}

    summary_files: List[Path] = []
    for root, _, files in os.walk(pass_root):
        for name in files:
            if name.endswith('_trace.json'):
                summary_files.append(Path(root) / name)

    if not summary_files:
        print(f"âš ï¸ pass@{k} æœªæ‰¾åˆ°æ±‡æ€»æ–‡ä»¶")
        return {}

    total_cases = 0
    evaluated_cases = 0
    correct_cases = 0

    for summary_path in summary_files:
        try:
            with summary_path.open('r', encoding='utf-8') as f:
                summary_data = json.load(f)
        except Exception as exc:
            print(f"âš ï¸ æ— æ³•è¯»å– {summary_path}: {exc}")
            continue

        total_cases += 1
        best_is_correct = summary_data.get('best_is_correct')
        if best_is_correct is None:
            continue
        evaluated_cases += 1
        if best_is_correct:
            correct_cases += 1

    accuracy = (correct_cases / evaluated_cases) if evaluated_cases else 0.0

    print("\n" + "=" * 60)
    print(f"ğŸ“Š pass@{k} æ±‡æ€»è¯„ä¼°")
    print(f"   è·¯å¾„: {pass_root}")
    print(f"   æ€»æ–‡ä»¶: {len(summary_files)}")
    print(f"   ç»Ÿè®¡æ¡ˆä¾‹: {total_cases}")
    print(f"   å·²è¯„ä¼°: {evaluated_cases}")
    print(f"   æ­£ç¡®: {correct_cases}")
    print(f"   å‡†ç¡®ç‡: {accuracy:.2%}" if evaluated_cases else "   å‡†ç¡®ç‡: æ— è¯„ä¼°ç»“æœ")
    print("=" * 60)

    return {
        'pass_at_k': k,
        'path': str(pass_root),
        'total_cases': total_cases,
        'evaluated_cases': evaluated_cases,
        'correct_cases': correct_cases,
        'accuracy': accuracy,
    }


def template_match_with_llm(actual_value, expected_value, path=""):
    """
    å¯¹äºé•¿åº¦è¶…è¿‡7ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ï¼Œä½¿ç”¨LLMè¿›è¡Œæ¨¡ç‰ˆåŒ¹é…

    Args:
        actual_value: å®é™…å€¼
        expected_value: æœŸæœ›å€¼
        path: å­—æ®µè·¯å¾„

    Returns:
        bool: æ˜¯å¦åŒ¹é…
    """
    # åªå¯¹å­—ç¬¦ä¸²è¿›è¡ŒLLMåŒ¹é…
    if not (isinstance(actual_value, str) and isinstance(expected_value, str)):
        return None

    # åªå¯¹é•¿åº¦è¶…è¿‡7ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²è¿›è¡ŒLLMåŒ¹é…
    if len(actual_value) <= 7 and len(expected_value) <= 7:
        return None

    prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªç­”æ¡ˆæ˜¯å¦åœ¨å«ä¹‰ä¸Šç­‰ä»·æˆ–åŒ¹é…ã€‚
    å³ä½¿è¡¨è¾¾æ–¹å¼ä¸åŒï¼Œåªè¦æ ¸å¿ƒå«ä¹‰ã€æ•°å€¼ã€é€»è¾‘å…³ç³»ä¸€è‡´å°±åº”è¯¥åˆ¤æ–­ä¸ºåŒ¹é…ã€‚
    è¯·åªå›ç­” 'åŒ¹é…' æˆ– 'ä¸åŒ¹é…'ã€‚

    ---
    æ ‡å‡†ç­”æ¡ˆï¼š
    {expected_value}
    ---
    æ¨¡å‹ç­”æ¡ˆï¼š
    {actual_value}
    ---
    """

    try:
        from gym.config.config import JUDGE_MODEL
        from gym.utils.client_manager import get_client

        evaluation_model = JUDGE_MODEL

        payload = {
            "model": evaluation_model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 5
        }

        client = get_client(evaluation_model)

        response = client.chat_completions_create(
            messages=payload["messages"],
            max_tokens=payload["max_tokens"]
        )

        result = response.choices[0].message.content.strip()
        is_match = result == "åŒ¹é…"

        print(f"  LLMæ¨¡ç‰ˆåŒ¹é… [{path}]: {result} ({'âœ…' if is_match else 'âŒ'})")
        return is_match

    except Exception as e:
        print(f"  âŒ LLMæ¨¡ç‰ˆåŒ¹é…å¤±è´¥ [{path}]: {e}")
        return None


def secondary_verification_with_llm(actual_value, expected_value, path=""):
    """
    äºŒæ¬¡éªŒè¯ï¼šå½“äººå·¥åŒ¹é…ç»“æœä¸ºæœªåŒ¹é…æ—¶ï¼Œä½¿ç”¨LLMè¿›è¡Œæœ€ç»ˆéªŒè¯
    æ”¯æŒæ‰€æœ‰ç±»å‹çš„å€¼ï¼ˆæ•°å€¼ã€å¸ƒå°”ã€å­—ç¬¦ä¸²ç­‰ï¼‰

    Args:
        actual_value: å®é™…å€¼
        expected_value: æœŸæœ›å€¼
        path: å­—æ®µè·¯å¾„

    Returns:
        bool: æ˜¯å¦åŒ¹é…ï¼ŒNoneè¡¨ç¤ºLLMéªŒè¯å¤±è´¥
    """
    # å°†å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºLLMæ¯”è¾ƒ
    actual_str = str(actual_value)
    expected_str = str(expected_value)
    

    prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªç­”æ¡ˆæ˜¯å¦åœ¨å«ä¹‰ä¸Šç­‰ä»·æˆ–åŒ¹é…ã€‚
    å³ä½¿è¡¨è¾¾æ–¹å¼ä¸åŒï¼Œåªè¦æ ¸å¿ƒå«ä¹‰ã€æ•°å€¼ã€é€»è¾‘å…³ç³»ä¸€è‡´å°±åº”è¯¥åˆ¤æ–­ä¸ºåŒ¹é…ã€‚
    è¯·åªå›ç­” 'åŒ¹é…' æˆ– 'ä¸åŒ¹é…'ã€‚

    ---
    æ ‡å‡†ç­”æ¡ˆï¼š{expected_str} 
    ---
    æ¨¡å‹ç­”æ¡ˆï¼š{actual_str} 
    ---
    """

    try:
        from gym.config.config import JUDGE_MODEL
        from gym.utils.client_manager import get_client

        evaluation_model = JUDGE_MODEL

        payload = {
            "model": evaluation_model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 5
        }

        client = get_client(evaluation_model)

        response = client.chat_completions_create(
            messages=payload["messages"],
            max_tokens=payload["max_tokens"]
        )

        result = response.choices[0].message.content.strip()
        is_match = result == "åŒ¹é…"

        print(f"  äºŒæ¬¡LLMéªŒè¯ [{path}]: {result} ({'âœ…' if is_match else 'âŒ'})")
        return is_match

    except Exception as e:
        print(f"  âŒ äºŒæ¬¡LLMéªŒè¯å¤±è´¥ [{path}]: {e}")
        return None


def calculate_answer_score(model_answer: Dict, golden_standard: Dict, tolerance: float = 0.05) -> Tuple[float, str, Dict]:
    """
    è®¡ç®—æ¨¡å‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…åˆ†æ•°

    è¿™æ˜¯ä¸€ä¸ªçº¯å‡½æ•°ï¼Œåªè´Ÿè´£è¯„åˆ†ç®—æ³•ï¼Œä¸æ¶‰åŠä»»ä½•å¤–éƒ¨ä¾èµ–ã€‚

    Args:
        model_answer: æ¨¡å‹çš„ç»“æ„åŒ–ç­”æ¡ˆ
        golden_standard: æ ‡å‡†ç­”æ¡ˆ
        tolerance: æ•°å€¼æ¯”è¾ƒçš„å®¹å·®

    Returns:
        Tuple[åˆ†æ•°, æ‘˜è¦, è¯¦ç»†ä¿¡æ¯]
    """

    def compare_values_recursive(actual, expected, path="", tolerance=0.05):
        """é€’å½’æ¯”è¾ƒå€¼ï¼Œè¿”å› (æ˜¯å¦åŒ¹é…, è¯¦ç»†ä¿¡æ¯å­—å…¸)"""
        current_path = path

        # å®šä¹‰æ•°å€¼è½¬æ¢å‡½æ•°
        def try_convert_to_number(value):
            """å°è¯•å°†å€¼è½¬æ¢ä¸ºæ•°å€¼ï¼Œå¦‚æœä¸èƒ½è½¬æ¢åˆ™è¿”å›åŸå€¼"""
            if isinstance(value, (int, float)):
                return value
            if isinstance(value, str):
                # å»é™¤å‰åç©ºæ ¼
                value = value.strip()
                try:
                    # å…ˆå°è¯•è½¬æ¢ä¸ºint
                    if '.' not in value and 'e' not in value.lower() and 'E' not in value:
                        return int(value)
                    # å†å°è¯•è½¬æ¢ä¸ºfloat
                    return float(value)
                except ValueError:
                    return value
            return value

        # å°è¯•æ•°å€¼è½¬æ¢
        expected_converted = try_convert_to_number(expected)
        actual_converted = try_convert_to_number(actual)

        # å­—å…¸æ¯”è¾ƒ
        if isinstance(expected, dict):
            if not isinstance(actual, dict):
                return False, {
                    current_path: {
                        "status": "type_mismatch",
                        "path": current_path,
                        "expected": expected,
                        "actual": actual
                    }
                }

            all_match = True
            all_details = {}

            for key, expected_value in expected.items():
                key_path = f"{current_path}.{key}" if current_path else key

                if key not in actual:
                    all_match = False
                    all_details[key_path] = {
                        "status": "missing",
                        "path": key_path,
                        "expected": expected_value,
                        "actual": None
                    }
                    continue

                match, details = compare_values_recursive(actual[key], expected_value, key_path, tolerance)
                if not match:
                    all_match = False

                # åˆå¹¶å­èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                all_details.update(details)

            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä½™çš„é”®
            for key in actual:
                if key not in expected:
                    key_path = f"{current_path}.{key}" if current_path else key
                    all_details[key_path] = {
                        "status": "unexpected",
                        "path": key_path,
                        "expected": None,
                        "actual": actual[key]
                    }

            return all_match, all_details

        # åˆ—è¡¨æ¯”è¾ƒ
        elif isinstance(expected, list):
            if not isinstance(actual, list):
                return False, {
                    current_path: {
                        "status": "type_mismatch",
                        "path": current_path,
                        "expected": expected,
                        "actual": actual
                    }
                }

            if len(actual) != len(expected):
                return False, {
                    current_path: {
                        "status": "length_mismatch",
                        "path": current_path,
                        "expected_length": len(expected),
                        "actual_length": len(actual),
                        "expected": expected,
                        "actual": actual
                    }
                }

            all_match = True
            all_details = {}

            for i, (actual_item, expected_item) in enumerate(zip(actual, expected)):
                item_path = f"{current_path}[{i}]" if current_path else f"[{i}]"
                match, details = compare_values_recursive(actual_item, expected_item, item_path, tolerance)
                if not match:
                    all_match = False

                # åˆå¹¶å­èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                all_details.update(details)

            return all_match, all_details

        # å¶å­èŠ‚ç‚¹æ¯”è¾ƒï¼ˆæ•°å€¼ã€å¸ƒå°”ã€å­—ç¬¦ä¸²ç­‰ï¼‰
        else:
            def apply_secondary_verification_if_needed(manual_match_result, match_type, result_detail):
                """å¦‚æœäººå·¥åŒ¹é…å¤±è´¥ï¼Œåº”ç”¨äºŒæ¬¡LLMéªŒè¯"""
                if manual_match_result:
                    # äººå·¥åŒ¹é…æˆåŠŸï¼Œç›´æ¥è¿”å›
                    result_detail["status"] = "match"
                    result_detail["match_type"] = match_type
                    return True, {current_path: result_detail}
                else:
                    # äººå·¥åŒ¹é…å¤±è´¥ï¼Œè¿›è¡ŒäºŒæ¬¡LLMéªŒè¯
                    secondary_match_result = secondary_verification_with_llm(actual, expected, current_path)
                    if secondary_match_result is True:
                        result_detail["status"] = "match"
                        result_detail["match_type"] = "secondary_llm_verification"
                        return True, {current_path: result_detail}
                    elif secondary_match_result is False:
                        result_detail["status"] = "mismatch"
                        result_detail["match_type"] = "secondary_llm_failed"
                        return False, {current_path: result_detail}
                    else:
                        # äºŒæ¬¡LLMéªŒè¯å¤±è´¥æˆ–ä¸é€‚ç”¨ï¼Œæœ€ç»ˆæ ‡è®°ä¸ºä¸åŒ¹é…
                        result_detail["status"] = "mismatch"
                        result_detail["match_type"] = "manual_and_llm_failed"
                        return False, {current_path: result_detail}

            result_detail = {"path": current_path, "expected": expected, "actual": actual}

            # ä½¿ç”¨ä¹‹å‰è½¬æ¢çš„æ•°å€¼
            expected_num = expected_converted
            actual_num = actual_converted

            # æ•°å€¼æ¯”è¾ƒï¼ˆåŒ…æ‹¬å­—ç¬¦ä¸²å½¢å¼çš„æ•°å­—ï¼‰
            if isinstance(expected_num, (int, float)) and isinstance(actual_num, (int, float)):
                expected_val = float(expected_num)
                actual_val = float(actual_num)

                result_detail["expected_num"] = expected_val
                result_detail["actual_num"] = actual_val

                # ä½¿ç”¨æ›´å®½æ¾çš„æ¯”è¾ƒç­–ç•¥
                # 1. å…ˆå°è¯•ç›´æ¥ç›¸ç­‰æ¯”è¾ƒ
                if expected_val == actual_val:
                    return apply_secondary_verification_if_needed(True, "exact", result_detail)

                # 2. ä¿ç•™ä¸¤ä½å°æ•°è¿›è¡Œæ¯”è¾ƒ
                expected_rounded = round(expected_val, 2)
                actual_rounded = round(actual_val, 2)
                result_detail["expected_rounded"] = expected_rounded
                result_detail["actual_rounded"] = actual_rounded

                if expected_rounded == actual_rounded:
                    result_detail["error"] = abs(actual_val - expected_val)
                    return apply_secondary_verification_if_needed(True, "rounded", result_detail)

                # 3. ä½¿ç”¨ç›¸å¯¹è¯¯å·®æ¯”è¾ƒï¼ˆå¯¹äºè¾ƒå¤§çš„æ•°å€¼ï¼‰
                if abs(expected_val) > 1:
                    relative_error = abs(actual_val - expected_val) / abs(expected_val)
                    result_detail["relative_error"] = relative_error
                    if relative_error <= tolerance:
                        return apply_secondary_verification_if_needed(True, "tolerance", result_detail)

                # 4. ä½¿ç”¨ç»å¯¹è¯¯å·®æ¯”è¾ƒï¼ˆå¯¹äºè¾ƒå°çš„æ•°å€¼ï¼‰
                else:
                    absolute_error = abs(actual_val - expected_val)
                    result_detail["absolute_error"] = absolute_error
                    if absolute_error <= tolerance:
                        return apply_secondary_verification_if_needed(True, "tolerance", result_detail)

                # æ•°å€¼ä¸åŒ¹é…ï¼Œè®°å½•è¯¯å·®ä¿¡æ¯å¹¶è¿›è¡ŒäºŒæ¬¡éªŒè¯
                if abs(expected_val) > 0:
                    result_detail["relative_error"] = abs(actual_val - expected_val) / abs(expected_val)
                result_detail["absolute_error"] = abs(actual_val - expected_val)
                return apply_secondary_verification_if_needed(False, "numeric_mismatch", result_detail)

            # å¸ƒå°”å€¼æ¯”è¾ƒ
            elif isinstance(expected, bool) and isinstance(actual, bool):
                manual_match = (expected == actual)
                return apply_secondary_verification_if_needed(manual_match, "exact" if manual_match else "boolean_mismatch", result_detail)

            # å­—ç¬¦ä¸²æ¯”è¾ƒ
            elif isinstance(expected, str) and isinstance(actual, str):
                # å…ˆè¿›è¡ŒåŸºæœ¬çš„äººå·¥åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™å’Œå‰åç©ºæ ¼ï¼‰
                expected_clean = expected.strip().lower()
                actual_clean = actual.strip().lower()
                manual_match = (expected_clean == actual_clean)
                return apply_secondary_verification_if_needed(manual_match, "exact" if manual_match else "string_mismatch", result_detail)

            # å…¶ä»–ç±»å‹çš„ç›´æ¥æ¯”è¾ƒ
            else:
                manual_match = (expected == actual)
                return apply_secondary_verification_if_needed(manual_match, "exact" if manual_match else "other_type_mismatch", result_detail)

    if not model_answer or not golden_standard:
        return 0.0, "ç¼ºå°‘ç­”æ¡ˆæ•°æ®", {}

    if not isinstance(model_answer, dict) or not isinstance(golden_standard, dict):
        return 0.0, "ç­”æ¡ˆæ ¼å¼ä¸åŒ¹é…", {}

    # è¿›è¡Œé€’å½’æ¯”è¾ƒ
    overall_match, field_details = compare_values_recursive(model_answer, golden_standard, "", tolerance)

    # è®¡ç®—åˆ†æ•°
    total_fields = _count_fields_recursive(golden_standard)
    matched_fields = _count_matches_from_details(field_details)

    if total_fields == 0:
        return 0.0, "æ ‡å‡†ç­”æ¡ˆä¸ºç©º", {}

    score = matched_fields / total_fields
    summary = f"åŒ¹é…å­—æ®µ: {matched_fields}/{total_fields} (å¾—åˆ†: {score:.2%})"

    return score, summary, field_details


# ä¸ºäº†ä¿æŒå‘åå…¼å®¹æ€§ï¼Œä¿ç•™è¿™ä¸ªå‡½æ•°
def evaluate_saved_traces(model_name=None, trace_dir=None, new_evaluate=False, lenient_mode=True):
    """
    å‘åå…¼å®¹çš„å‡½æ•°ï¼Œç°åœ¨å§”æ‰˜ç»™æ–°çš„è¯„ä¼°æœåŠ¡

    å»ºè®®ç›´æ¥ä½¿ç”¨ evaluation_service æ¨¡å—ä¸­çš„å‡½æ•°
    """
    print("âš ï¸ æ³¨æ„: evaluate_saved_traces å‡½æ•°å·²è¢«å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ evaluation_service æ¨¡å—")

    from gym.core.evaluation_service import evaluate_traces
    result = evaluate_traces(
        trace_dir=trace_dir,
        model_name=model_name,
        force_reextract=new_evaluate,
        lenient_mode=lenient_mode,
    )

    if result['success']:
        return result
    else:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {result.get('error', 'Unknown error')}")
        return None


if __name__ == "__main__":
    """ä½¿ç”¨ç¤ºä¾‹ - ç°åœ¨å§”æ‰˜ç»™æ–°çš„è¯„ä¼°æœåŠ¡"""
    print("ğŸ”„ é‡å®šå‘åˆ°æ–°çš„è¯„ä¼°æœåŠ¡...")

    import sys
    from gym.core.evaluation_service import evaluate_traces

    if len(sys.argv) > 1:
        model_name = sys.argv[1]
        print(f"ğŸ“Š è¯„ä¼°æ¨¡å‹: {model_name}")
        result = evaluate_traces(model_name=model_name, force_reextract=True, lenient_mode=True)
    else:
        print("ğŸ“Š è¯„ä¼°æ‰€æœ‰æ¨¡å‹")
        result = evaluate_traces(force_reextract=True, lenient_mode=True)
