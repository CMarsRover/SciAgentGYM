#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å·¥å…·æ³¨å†Œæµ‹è¯•æ¨¡å—

æµ‹è¯•æ‰€æœ‰æ•°æ®é›†æ–‡ä»¶ä¸­çš„å·¥å…·æ³¨å†Œæƒ…å†µï¼ŒéªŒè¯å·¥å…·åŠ è½½å’Œæ³¨å†Œæµç¨‹çš„æ­£ç¡®æ€§ã€‚
"""
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from gym.core.tool_loader import load_tools_for_case, register_tools_to_env


def test_all_tools_registration(
    dataset_dir: str = "gym/dataset",
    output_file: str = "gym/dataset/tool_registration_test_results.json"
):
    """
    æµ‹è¯•æ‰€æœ‰æ•°æ®é›†æ–‡ä»¶ä¸­çš„å·¥å…·æ³¨å†Œæƒ…å†µã€‚
    
    å‚æ•°:
        dataset_dir: æ•°æ®é›†ç›®å½•è·¯å¾„
        output_file: è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„
    
    è¿”å›:
        dict: æµ‹è¯•ç»“æœç»Ÿè®¡
    """
    dataset_path = project_root / dataset_dir
    output_path = project_root / output_file
    
    if not dataset_path.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_path}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶
    json_files = list(dataset_path.glob("*.json"))
    if not json_files:
        print(f"âŒ åœ¨ {dataset_path} ä¸­æœªæ‰¾åˆ° JSON æ–‡ä»¶")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(json_files)} ä¸ªæ•°æ®é›†æ–‡ä»¶")
    print("=" * 80)
    
    all_results = {
        "test_timestamp": str(Path(__file__).stat().st_mtime),
        "dataset_dir": str(dataset_dir),
        "total_files": len(json_files),
        "files": []
    }
    
    total_cases = 0
    total_success = 0
    total_failed = 0
    
    for json_file in json_files:
        print(f"\nğŸ“‚ å¤„ç†æ–‡ä»¶: {json_file.name}")
        file_result = {
            "filename": json_file.name,
            "total_cases": 0,
            "success_cases": 0,
            "failed_cases": 0,
            "failed_details": []
        }
        
        try:
            with open(json_file, "r", encoding="utf-8") as f:
                cases = json.load(f)
            
            if not isinstance(cases, list):
                print(f"  âš ï¸ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šé¡¶å±‚ä¸æ˜¯åˆ—è¡¨")
                file_result["error"] = "æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šé¡¶å±‚ä¸æ˜¯åˆ—è¡¨"
                all_results["files"].append(file_result)
                continue
            
            file_result["total_cases"] = len(cases)
            total_cases += len(cases)
            
            print(f"  ğŸ“Š å…± {len(cases)} ä¸ªæµ‹è¯•æ¡ˆä¾‹")
            
            for idx, test_case in enumerate(cases):
                case_id = test_case.get("id") or test_case.get("metadata", {}).get("case_id") or idx + 1
                
                try:
                    # å°è¯•åŠ è½½å·¥å…·
                    tool_protocols, function_map = load_tools_for_case(test_case)
                    
                    if not tool_protocols:
                        raise ValueError("æœªæ‰¾åˆ°ä»»ä½•å·¥å…·åè®®")
                    
                    if not function_map:
                        raise ValueError("æœªæ‰¾åˆ°ä»»ä½•å·¥å…·å‡½æ•°")
                    
                    # å°è¯•æ³¨å†Œåˆ°ç¯å¢ƒ
                    env, tool_instances, tools_schema, tool_registry = register_tools_to_env(
                        tool_protocols,
                        function_map
                    )
                    
                    if not tool_instances:
                        raise ValueError("å·¥å…·æ³¨å†Œå¤±è´¥ï¼šæœªåˆ›å»ºä»»ä½•å·¥å…·å®ä¾‹")
                    
                    total_success += 1
                    file_result["success_cases"] += 1
                    
                    if (idx + 1) % 100 == 0:
                        print(f"    âœ“ å·²å¤„ç† {idx + 1}/{len(cases)} ä¸ªæ¡ˆä¾‹")
                
                except Exception as e:
                    total_failed += 1
                    file_result["failed_cases"] += 1
                    
                    # è®°å½•å¤±è´¥è¯¦æƒ…
                    metadata = test_case.get("metadata") or {}
                    failed_detail = {
                        "case_id": case_id,
                        "subject": metadata.get("subject"),
                        "topic": metadata.get("topic"),
                        "error_type": type(e).__name__,
                        "error_message": str(e),
                        "usage_tool_protocol_count": len(test_case.get("usage_tool_protocol", [])),
                    }
                    
                    # è®°å½•å·¥å…·è·¯å¾„ä¿¡æ¯
                    tool_paths = []
                    for tool in test_case.get("usage_tool_protocol", []):
                        if isinstance(tool, dict):
                            addl = tool.get("additionalProperties") or {}
                            tool_path = addl.get("function_path")
                            if tool_path:
                                tool_paths.append(tool_path)
                    failed_detail["tool_paths"] = tool_paths
                    
                    file_result["failed_details"].append(failed_detail)
                    
                    if file_result["failed_cases"] <= 5:  # åªæ‰“å°å‰5ä¸ªå¤±è´¥æ¡ˆä¾‹
                        print(f"    âŒ æ¡ˆä¾‹ {case_id} å¤±è´¥: {str(e)[:100]}")
            
            print(f"  âœ… æˆåŠŸ: {file_result['success_cases']}, âŒ å¤±è´¥: {file_result['failed_cases']}")
            
        except Exception as e:
            print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            file_result["error"] = str(e)
        
        all_results["files"].append(file_result)
    
    # æ±‡æ€»ç»Ÿè®¡
    all_results["summary"] = {
        "total_cases": total_cases,
        "total_success": total_success,
        "total_failed": total_failed,
        "success_rate": f"{(total_success / total_cases * 100):.2f}%" if total_cases > 0 else "0%"
    }
    
    # ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ±‡æ€»
    print("\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•æ±‡æ€»:")
    print(f"  æ€»æ¡ˆä¾‹æ•°: {total_cases}")
    print(f"  âœ… æˆåŠŸ: {total_success}")
    print(f"  âŒ å¤±è´¥: {total_failed}")
    print(f"  æˆåŠŸç‡: {all_results['summary']['success_rate']}")
    print(f"  ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    print("=" * 80)
    
    return all_results


def test_single_case(dataset_file: str = None):
    """
    æµ‹è¯•å•ä¸ªæ¡ˆä¾‹çš„å·¥å…·æ³¨å†Œã€‚
    
    å‚æ•°:
        dataset_file: æ•°æ®é›†æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨ refine_merged_questions_augmented.json
    """
    if dataset_file is None:
        dataset_path = project_root / "gym" / "dataset" / "refine_merged_questions_augmented.json"
    else:
        dataset_path = Path(dataset_file)
    
    if not dataset_path.exists():
        print(f"âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
        return
    
    with open(dataset_path, "r", encoding="utf-8") as f:
        test_cases = json.load(f)
    
    if not test_cases:
        print("âŒ æ•°æ®é›†ä¸ºç©º")
        return
    
    print(f"ğŸ“‹ æµ‹è¯•å•ä¸ªæ¡ˆä¾‹ (ID: {test_cases[0].get('id', 'unknown')})")
    
    # æ­¥éª¤1: åŠ è½½å·¥å…·åè®®å’Œå‡½æ•°
    tool_protocols, function_map = load_tools_for_case(test_cases[0])
    
    # æ­¥éª¤2: æ³¨å†Œåˆ°ç¯å¢ƒ
    env, tool_instances, tools_schema, tool_registry = register_tools_to_env(
        tool_protocols,
        function_map
    )
    
    print(f"âœ… æˆåŠŸæ³¨å†Œ {len(tool_instances)} ä¸ªå·¥å…·")
    print(f"ğŸ“ tool_instances: {tool_instances}")
    print(f"ğŸ“ tools_schema: {tools_schema}")
    print(f"ğŸ“ å·¥å…·åˆ—è¡¨: {list(tool_registry.keys())}")
    
    return env, tool_instances, tools_schema, tool_registry


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="å·¥å…·æ³¨å†Œæµ‹è¯•")
    parser.add_argument("--test-all", action="store_true", help="æµ‹è¯•æ‰€æœ‰æ•°æ®é›†æ–‡ä»¶")
    parser.add_argument("--dataset-dir", default="gym/dataset", help="æ•°æ®é›†ç›®å½•")
    parser.add_argument("--output", default="gym/dataset/tool_registration_test_results.json", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--single", action="store_true", help="æµ‹è¯•å•ä¸ªæ¡ˆä¾‹")
    parser.add_argument("--file", default=None, help="æŒ‡å®šæ•°æ®é›†æ–‡ä»¶ï¼ˆç”¨äº --singleï¼‰")
    
    args = parser.parse_args()
    
    if args.test_all:
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        test_all_tools_registration(dataset_dir=args.dataset_dir, output_file=args.output)
    elif args.single:
        # å•ä¸ªæ¡ˆä¾‹æµ‹è¯•
        test_single_case(dataset_file=args.file)
    else:
        # é»˜è®¤è¿è¡Œå•ä¸ªæ¡ˆä¾‹æµ‹è¯•
        test_single_case()
